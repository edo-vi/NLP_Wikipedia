{{short description|1950 article by Alan Turing on artificial intelligence that introduced the Turing test}}
{{Use dmy dates|date=April 2018}}
{{Use British English|date=April 2018}}
"'''Computing Machinery and Intelligence'''" is a seminal paper written by [[Alan Turing]] on the topic of [[artificial intelligence]]. The paper, published in 1950 in ''[[Mind (journal)|Mind]]'', was the first to introduce his concept of what is now known as the [[Turing test]] to the general public.

Turing's paper considers the question "Can machines think?" Turing says that since the words "think" and "machine" cannot be clearly defined we should "replace the question by another, which is closely related to it and is expressed in relatively unambiguous words."<ref>{{Harvnb|Turing|1950|p=433}}</ref> To do this, he must first find a simple and unambiguous idea to replace the word "think", second he must explain exactly which "machines" he is considering, and finally, armed with these tools, he formulates a new question, related to the first, that he believes he can answer in the affirmative.

==Turing's test==
[[File:Turing Test version 3.png|thumb|The "standard interpretation" of the Turing Test, in which the interrogator is tasked with trying to determine which player is a computer and which is a human]]
{{Main|Turing test}}

Rather than trying to determine if a machine is thinking, Turing suggests we should ask if the machine can win a game, called the "[[Turing test#Imitation game|Imitation Game]]". The original Imitation game, that Turing described, is a simple party game involving three players. Player A is a man, player B is a woman and player C (who plays the role of the interrogator) can be of either sex. In the Imitation Game, player C is unable to see either player A or player B (and knows them only as X and Y), and can communicate with them only through written notes or any other form that does not give away any details about their gender. By asking questions of player A and player B, player C tries to determine which of the two is the man and which is the woman. Player A's role is to trick the interrogator into making the wrong decision, while player B attempts to assist the interrogator in making the right one.<ref>{{Citation |last1=Oppy |first1=Graham |title=The Turing Test |date=2021 |url=https://plato.stanford.edu/archives/win2021/entriesuring-test/ |encyclopedia=The Stanford Encyclopedia of Philosophy |editor-last=Zalta |editor-first=Edward N. |access-date=2023-08-06 |edition=Winter 2021 |publisher=Metaphysics Research Lab, Stanford University |last2=Dowe |first2=David}}</ref>
  
Turing proposes a variation of this game that involves the computer: {{' "}}What will happen when a machine takes the part of A in this game?" Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, 'Can machines think?{{" '}}<ref>{{Harvnb|Turing|1950|p=434}}</ref> 
So the modified game becomes one that involves three participants in isolated rooms: a computer (which is being tested), a human, and a (human) judge. The human judge can converse with both the human and the computer by typing into a terminal. Both the computer and human try to convince the judge that they are the human. If the judge cannot consistently tell which is which, then the computer wins the game.<ref>This describes the simplest version of the test. For a more detailed discussion, see [[Turing test#Versions|Versions of the Turing test]].</ref>

As [[Stevan Harnad]] notes,<ref>{{Citation |chapter-url=http://eprints.ecs.soton.ac.uk/12954/ |first=Stevan |last=Harnad |year=2008 |chapter=The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence |editor1-last=Epstein |editor1-first=Robert |editor2-last=Peters |editor2-first=Grace |title=The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer |publisher=Kluwer }}</ref> the question has become "Can machines do what we (as thinking entities) can do?" In other words, Turing is no longer asking whether a machine can "think"; he is asking whether a machine can ''act'' indistinguishably<ref>{{Citation |url=http://cogprints.org/2615/ |first=Stevan |last=Harnad |year=2001 |title=Minds, Machines, and Turing: The Indistinguishability of Indistinguishables |journal=Journal of Logic, Language and Information |volume=9 |issue=4 |pages=425–445 |postscript=. |doi=10.1023/A:1008315308862 |s2cid=1911720 }}</ref> from the way a thinker acts. This question avoids the difficult philosophical problem of pre-defining the verb "to think" and focuses instead on the performance capacities that being able to think makes possible, and how a causal system can generate them.

Some have taken Turing's question to have been "Can a computer, communicating over a teleprinter, fool a person into believing it is human?"<ref name=NMR>Wardrip-Fruin, Noah and Nick Montfort, ed (2003). The New Media Reader. The MIT Press. {{ISBN|0-262-23227-8}}.</ref> but it seems clear that Turing was not talking about fooling people but about generating human cognitive capacity.<ref>{{Citation |url=http://cogprints.org/1584/ |first=Stevan |last=Harnad |title=The Turing Test Is Not A Trick: Turing Indistinguishability Is A Scientific Criterion |journal=SIGART Bulletin |volume=3 |issue=4 |year=1992 |pages=9–10 |postscript=. |doi=10.1145/141420.141422 |s2cid=36356326 }}</ref>

==Digital machines==
{{See also|Turing machine|Church–Turing thesis}}

Turing also notes that we need to determine which "machines" we wish to consider. He points out that a human [[cloning|clone]], while man-made, would not provide a very interesting example. Turing suggested that we should focus on the capabilities of digital machinery—machines which manipulate the binary digits of 1 and 0, rewriting them into memory using simple rules. He gave two reasons.

First, there is no reason to speculate whether or not they can exist. They already did in 1950.

Second, digital machinery is "universal". Turing's research into the [[theory of computation|foundations of computation]] had proved that a digital computer can, in theory, simulate the behaviour of any other digital machine, given enough memory and time. (This is the essential insight of the [[Church–Turing thesis]] and the [[universal Turing machine]].) Therefore, if ''any'' digital machine can "act like it is thinking" then, ''every'' sufficiently powerful digital machine can. Turing writes, "all digital computers are in a sense equivalent."<ref name=P442>{{Harvnb|Turing|1950|p=442}}</ref>

This allows the original question to be made even more specific. Turing now restates the original question as "Let us fix our attention on one particular digital computer C. Is it true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate programme, C can be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man?"<ref name=P442/>

Hence, Turing states that the focus is not on "whether all digital computers would do well in the game nor whether the computers that are presently available would do well, but whether there are imaginable computers which would do well".<ref name=P436>{{Harvnb|Turing|1950|p=436}}</ref> What is more important is to consider the advancements possible in the state of our machines today regardless of whether we have the available resource to create one or not.

==Nine common objections==
{{See also|Philosophy of artificial intelligence}}

Having clarified the question, Turing turned to answering it: he considered the following nine common objections, which include all the major arguments against artificial intelligence raised in the years since his paper was first published.<ref>{{Harvnb|Turing|1950}} see {{Harvnb|Russell|Norvig|2003|p=948}} where comment "Turing examined a wide variety of possible objections to the possibility of intelligent machines, including virtually all of those that have been raised in the half century since his paper appeared."</ref>

#''[[Religious]] Objection'': This states that thinking is a function of man's [[Immortality|immortal]] [[soul]]; therefore, a machine cannot think.  "In attempting to construct such machines," wrote Turing, "we should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children: rather we are, in either case, instruments of His will providing mansions for the souls that He creates."
#'' 'Heads in the Sand' Objection'': "The consequences of machines thinking would be too dreadful.  Let us hope and believe that they cannot do so."  This thinking is popular among intellectual people, as they believe superiority derives from higher intelligence and [[Existential risk from artificial general intelligence|the possibility of being overtaken is a threat]] (as machines have efficient memory capacities and processing speed, machines exceeding the learning and knowledge capabilities are highly probable). This objection is a fallacious [[appeal to consequences]], confusing what should not be with what can or cannot be (Wardrip-Fruin, 56).
#''The [[Mathematics|Mathematical]] Objection'': This objection uses mathematical theorems, such as [[Gödel's incompleteness theorem]], to show that there are limits to what questions a computer system based on [[logic]] can answer.  Turing suggests that humans are too often wrong themselves and pleased at the fallibility of a machine.  (This argument would be made again by philosopher [[John Lucas (philosopher)|John Lucas]] in 1961 and [[physicist]] [[Roger Penrose]] in 1989.)<ref>{{Harvnb|Lucas|1961}}, {{Harvnb|Penrose|1989}}, {{Harvnb|Hofstadter|1979|pp=471–473,476–477}} and {{Harvnb|Russell|Norvig|2003|pp=949–950}}. Russell and Norvig identify Lucas and Penrose's arguments as being the same one answered by Turing.</ref>
#''Argument From [[Consciousness]]'': This argument, suggested by Professor [[Geoffrey Jefferson]] in his 1949 [[Lister Medal|Lister Oration]] (acceptance speech for his 1948 award of Lister Medal<ref>{{Cite journal |year=1948 |title=Announcements |journal=Nature |volume=162 |issue=4108 |pages=138 |bibcode=1948Natur.162U.138. |doi=10.1038/162138e0 |doi-access=free}}</ref>) states that "not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain."<ref>{{Cite journal |last=Jefferson |first=Geoffrey |date=1949-06-25 |title=The Mind of Mechanical Man |journal=British Medical Journal |volume=1 |issue=4616 |pages=1105–1110 |doi=10.1136/bmj.1.4616.1105 |issn=0007-1447 |pmc=2050428 |pmid=18153422}}</ref>  Turing replies by saying that we have no way of knowing that any individual other than ourselves experiences emotions, and that therefore we should accept the test.  He adds, "I do not wish to give the impression that I think there is no mystery about consciousness ... [b]ut I do not think these mysteries necessarily need to be solved before we can answer the question [of whether machines can think]." (This argument, that a computer can't have ''conscious experiences'' or ''understanding'', would be made in 1980 by philosopher [[John Searle]] in his [[Chinese room]] argument. Turing's reply is now known as the "[[problem of other minds|other minds]] reply". See also [[Philosophy of artificial intelligence#Can a machine have a mind, consciousness and mental states?|Can a machine have a mind?]] in the [[philosophy of AI]].)<ref>{{Harvnb|Searle|1980}} and {{Harvnb|Russell|Norvig|2003|pp=958–960}}, who identify Searle's argument with the one Turing answers.</ref>
#''Arguments from various disabilities''. These arguments all have the form "a computer will never do ''X''". Turing offers a selection:<blockquote>Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humour, tell right from wrong, make mistakes, fall in love, enjoy strawberries and cream, make someone fall in love with it, learn from experience, use words properly, be the subject of its own thought, have as much diversity of behaviour as a man, do something really new.</blockquote>Turing notes that "no support is usually offered for these statements," and that they depend on naive assumptions about how versatile machines may be in the future, or are "disguised forms of the argument from consciousness." He chooses to answer a few of them:
##''Machines cannot make mistakes.'' He notes it's easy to program a machine to appear to make a mistake.
##''A machine cannot be the subject of its own thought'' (or can't be [[self-aware]]). A program which can report on its internal states and processes, in the simple sense of a [[debugger]] program, can certainly be written. Turing asserts "a machine can undoubtably be its own subject matter."
##''A machine cannot have much diversity of behaviour''. He notes that, with enough storage capacity, a computer can behave in an astronomical number of different ways.
#''[[Ada Lovelace|Lady Lovelace]]'s Objection'': One of the most famous objections states that computers are incapable of originality. This is largely because, according to [[Ada Lovelace]], machines are incapable of independent learning.<blockquote>The Analytical Engine has no pretensions whatever to ''originate'' anything. It can do whatever ''we know how to order it'' to perform. It can follow analysis; but it has no power of anticipating any analytical relations or truths.<ref>[[wikisource:Scientific_Memoirs/3/Sketch_of_the_Analytical_Engine_invented_by_Charles_Babbage,_Esq./Notes_by_the_Translator|Scientific Memoirs edited by Richard Taylor (1781-1858), Volume 3, Sketch of the Analytical Engine invented by Charles Babbage, Esq, Notes by the Translator, by Augusta Ada Lovelace. 1843]]</ref></blockquote> Turing suggests that Lovelace's objection can be reduced to the assertion that computers "can never take us by surprise" and argues that, to the contrary, computers could still surprise humans, in particular where the consequences of different facts are not immediately recognizable. Turing also argues that Lady Lovelace was hampered by the context from which she wrote, and if exposed to more contemporary scientific knowledge, it would become evident that the brain's storage is quite similar to that of a computer.
#''Argument from continuity in the nervous system'': Modern [[neurological]] research has shown that the brain is not digital. Even though [[neuron]]s fire in an all-or-nothing pulse, both the exact timing of the pulse and the probability of the pulse occurring have analog components. Turing acknowledges this, but argues that any analog system can be simulated to a reasonable degree of accuracy given enough computing power. ([[Philosopher]] [[Hubert Dreyfus]] would make this argument against "the biological assumption" in 1972.)<ref>{{Harvnb|Dreyfus|1979|p=156}}</ref>
#''Argument from the informality of behaviour'': This argument states that any system governed by laws will be predictable and therefore not truly intelligent. Turing replies by stating that this is confusing laws of behaviour with general rules of conduct, and that if on a broad enough scale (such as is evident in man) machine behaviour would become increasingly difficult to predict. He argues that, just because we can't immediately see what the laws are, does not mean that no such laws exist. He writes "we certainly know of no circumstances under which we could say, 'we have searched enough. There are no such laws.'". ([[Hubert Dreyfus]] would argue in 1972 that human reason and problem solving was not based on formal rules, but instead relied on instincts and awareness that would never be captured in rules. More recent AI research in [[robotics]] and [[computational intelligence]] attempts to find the complex rules that govern our "informal" and unconscious skills of perception, mobility and pattern matching. See [[Dreyfus' critique of AI]]).<ref>{{Harvnb|Dreyfus|1972}}, {{Harvnb|Dreyfus|Dreyfus|1986}}, {{Harvnb|Moravec|1988}} and {{Harvnb|Russell|Norvig|2003|pp=51–52}}, who identify Dreyfus' argument with the one Turing answers.</ref> This rejoinder also includes the [[Turing's Wager]] argument.
#''[[Extra-sensory perception]]'': In 1950, extra-sensory perception was an active area of research and Turing chooses to give ESP the benefit of the doubt, arguing that conditions could be created in which [[Telepathy|mind-reading]] would not affect the test. Turing admitted to "overwhelming statistical evidence" for telepathy, likely referring to early 1940s experiments by [[Samuel Soal]], a member of the [[Society for Psychical Research]].<ref>{{Citation |last=Leavitt |first=David |title=Turing and the paranormal |date=2017-01-26 |url=https://academic.oup.com/book/40646/chapter/348321617 |work=The Turing Guide |access-date=2023-07-23 |publisher=Oxford University Press |language=en |doi=10.1093/oso/9780198747826.003.0042 |isbn=978-0-19-874782-6}}</ref>

==Learning machines==
{{see also|Machine learning}}
In the final section of the paper Turing details his thoughts about the Learning Machine that could play the imitation game successfully.

Here Turing first returns to Lady Lovelace's objection that the machine can only do what we tell it to do and he likens it to a situation where a man "injects" an idea into the machine to which the machine responds and then falls off into quiescence. He extends on this thought by an analogy to an atomic pile of less than critical size which is to be considered the machine and an injected idea is to correspond to a [[neutron]] entering the pile from outside the pile; the neutron will cause a certain disturbance which eventually dies away. Turing then builds on that analogy and mentions that if the [[Critical mass|size]] of the pile were to be sufficiently large then a neutron entering the pile would cause a disturbance that would continue to increase until the whole pile were destroyed, the pile would be supercritical. Turing then asks the question as to whether this analogy of a super critical pile could be extended to a human mind and then to a machine. He concludes that such an analogy would indeed be suitable for the human mind with "There does seem to be one for the human mind. The majority of them seem to be "subcritical," i.e., to correspond in this analogy to piles of sub critical size. An idea presented to such a mind will on average give rise to less than one idea in reply. A smallish proportion are supercritical. An idea presented to such a mind that may give rise to a whole "theory" consisting of secondary, tertiary and more remote ideas". He finally asks if a machine could be made to be supercritical.

Turing then mentions that the task of being able to create a machine that could play the imitation game is one of programming and he postulates that by the end of the century it will indeed be technologically possible to program a machine to play the game. He then mentions that in the process of trying to imitate an adult human mind it becomes important to consider the processes that lead to the adult mind being in its present state; which he summarizes as:
::1. The initial state of the mind, say at birth,
::2. The education to which it has been subjected,
::3. Other experience, not to be described as education, to which it has been subjected.
Given this process he asks whether it would be more appropriate to program a child's mind instead of an adults mind and then subject the child mind to a period of education. He likens the child to a newly bought notebook and speculates that due to its simplicity it would be more easily programmed. The problem then is broken down into two parts, the programming of a child mind and its education process. He mentions that a child mind would not be expected as desired by the experimenter (programmer) at the first attempt. A learning process that involves a method of reward and punishment must be in place that will select desirable patterns in the mind. This whole process, Turing mentions, to a large extent is similar to that of evolution by natural selection where the similarities are:
::Structure of the child machine = hereditary material
::Changes of the child machine = mutations
::Natural selection = judgment of the experimenter
Following this discussion Turing addresses certain specific aspects of the learning machine: 
:* Nature of inherent complexity: The child machine could either be one that is as simple as possible, merely maintaining consistency with general principles, or the machine could be one with a complete system of logical inference programmed into it. This more complex system is explained by Turing as "..would be such that the machines store would be largely occupied with definitions and [[proposition]]s. The propositions would have various kinds of status, e.g., well-established facts, conjectures, mathematically proved theorems, statements given by an authority, expressions having the logical form of proposition but not belief-value. Certain propositions may be described as "imperatives." The machine should be so constructed that as soon as an imperative is classed as "well established" the appropriate action automatically takes place.". Despite this built-in logic system the logical inference programmed in would not be one that is formal, rather it would be one that is more pragmatic. In addition the machine would build on its built-in logic system by a method of "scientific induction".

:* Ignorance of the experimenter: An important feature of a learning machine that Turing points out is the ignorance of the teacher of the machines' internal state during the learning process. This is in contrast to a conventional discrete state machine where the objective is to have a clear understanding of the internal state of the machine at every moment during the computation. The machine will be seen to be doing things that we often cannot make sense of or something that we consider to be completely random. Turing mentions that this specific character bestows upon a machine a certain degree of what we consider to be intelligence, in that intelligent behaviour consists of a deviation from the complete determinism of conventional computation but only so long as the deviation does not give rise to pointless loops or random behaviour.

:* The importance of random behaviour: Though Turing cautions us of random behaviour he mentions that inculcating an element of randomness in a learning machine would be of value in a system. He mentions that this could be of value where there might be multiple correct answers or ones where it might be such that a systematic approach would investigate several unsatisfactory solutions to a problem before finding the optimal solution which would entail the systematic process inefficient. Turing also mentions that the process of evolution takes the path of random mutations in order to find solutions that benefit an organism but he also admits that in the case of evolution the systematic method of finding a solution would not be possible.

Turing concludes by speculating about a time when machines will compete with humans on numerous intellectual tasks and suggests tasks that could be used to make that start. Turing then suggests that abstract tasks such as playing chess could be a good place to start another method which he puts as "..it is best to provide the machine with the best sense organs that money can buy, and then teach it to understand and speak English.".

An examination of the development in [[artificial intelligence]] that has followed reveals that the learning machine did take the abstract path suggested by Turing as in the case of [[Deep Blue (chess computer)|Deep Blue]], a chess playing computer developed by [[IBM]] and one which defeated the world champion [[Garry Kasparov]] (though, this too is controversial) and the numerous computer chess games which can outplay most amateurs.<ref name="ParsingTT2008">{{cite book|last1=Epstein|first1=Robert|last2=Roberts|first2=Gary|last3=Beber|first3=Grace|title=Parsing the Turing Test:Philosophical and Methodological Issues in the Quest for the Thinking Computer|date=2008|publisher=Springer|isbn=978-1-4020-6710-5|page=65|url=https://books.google.com/books?id=aggUJL_5_oQC}}</ref> As for the second suggestion Turing makes, it has been likened by some authors as a call to finding a [[simulacrum]] of human cognitive development.<ref name="ParsingTT2008"/> And such attempts at finding the underlying algorithms by which children learn of the features of the world around them are only beginning to be made.<ref name="ParsingTT2008"/><ref>{{cite book|last1=Gopnik|first1=Alison|last2=Meltzoff.|first2=Andrew N.|title=Words, thoughts, and theories.|series=Learning, Development, and Conceptual Change|date=1997|publisher=MIT Press|isbn=9780262071758|url=http://mitpress.mit.edu/books/words-thoughts-and-theories}}</ref><ref>{{cite journal|last1=Meltzoff|first1=Andrew N.|title=Origins of theory of mind, cognition and communication.|journal=Journal of Communication Disorders|date=1999|volume=32|issue=4|pages=251–269|url=http://ilabs.washington.edu/meltzoff/pdf/99Meltzoff_JCommDisord.pdf|doi=10.1016/S0021-9924(99)00009-X|pmid=10466097|pmc=3629913}}</ref>

==Notes==
{{reflist}}

==References==
* {{Citation | first = Rodney | last = Brooks | title = Elephants Don't Play Chess | journal = Robotics and Autonomous Systems | volume=6 | issue = 1–2 | year =1990 | pages = 3–15 | author-link=Rodney Brooks | url=http://people.csail.mit.edu/brooks/papers/elephants.pdf | access-date=2007-08-30 | doi = 10.1016/S0921-8890(05)80025-9| citeseerx = 10.1.1.588.7539 }}
* {{Crevier 1993}}
* {{Citation | last = Dreyfus | first = Hubert  | title = What Computers Can't Do | year =1972 | publisher = MIT Press | location = New York | author-link = Hubert Dreyfus | isbn = 978-0-06-011082-6 | title-link = What Computers Can't Do  }}
* {{Citation | last1 = Dreyfus | first1 = Hubert | last2 = Dreyfus | first2 = Stuart | year = 1986 | title = Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer | publisher = Blackwell | location = Oxford, UK | author-link = Hubert Dreyfus }}
* {{Citation | last = Dreyfus | first = Hubert  | title = What Computers ''Still'' Can't Do | year =1979 | publisher = MIT Press | location = New York | author-link = Hubert Dreyfus }}.
* {{Citation | doi = 10.1016/j.artmed.2008.08.008 | last1 = Harnad | first1 = Stevan | last2 = Scherzer | first2 = Peter  | title = First, Scale Up to the Robotic Turing Test, Then Worry About Feeling | journal = Artificial Intelligence in Medicine | volume = 44 | issue = 2 | year = 2008 | pages = 83–9 | author-link=Stevan Harnad | url=http://eprints.ecs.soton.ac.uk/14430/ | pmid = 18930641 | citeseerx = 10.1.1.115.4269 }}.
* {{Citation | first = John | last = Haugeland | year = 1985 | title = Artificial Intelligence: The Very Idea | publisher=MIT Press | author-link = John Haugeland| location= Cambridge, Mass.}}.
* {{Citation | first = Hans | last = Moravec | year = 1976 | url = http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html | title = The Role of Raw Power in Intelligence | author-link = Hans Moravec | access-date = 7 November 2007 | archive-url = https://web.archive.org/web/20160303232511/http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html | archive-date = 3 March 2016 | url-status = dead }}
* {{Citation |last=Hofstadter |first=Douglas |title=Gödel, Escher, Bach: an Eternal Golden Braid |year=1979 |author-link=Douglas Hofstadter |title-link=Gödel, Escher, Bach }}.
* {{Citation |last=Lucas |first=John |author-link=John Lucas (philosopher) |year=1961 |contribution=Minds, Machines and Gödel |editor-last=Anderson |editor-first=A.R. |title=Minds and Machines |url=http://users.ox.ac.uk/~jrlucas/Godel/mmg.html}}
* {{Citation |last=Moravec |first=Hans |year=1988 |title=Mind Children |publisher=Harvard University Press |author-link=Hans Moravec }}
* {{Citation |last=Penrose |first=Roger |title=The Emperor's New Mind: Concerning Computers, Minds, and The Laws of Physics |publisher=Oxford University Press |year=1989 |isbn=978-0-14-014534-2 |author-link=Roger Penrose |title-link=The Emperor's New Mind}}
* {{Russell Norvig 2003}}
* {{Citation |doi=10.1017/S0140525X00005756 |first=John |last=Searle |url=https://home.csulb.edu/~cwallis/382/readings/482/searle.minds.brains.programs.bbs.1980.pdf |title=Minds, Brains and Programs |journal=Behavioral and Brain Sciences |volume=3 |issue=3 |pages=417–457 |year=1980 |s2cid=55303721 |author-link=John Searle}}
* {{Citation | last = Turing | first = Alan | title = Computing Machinery and Intelligence | journal=Mind | volume = LIX | issue = 236 |date = October 1950| pages= 433–460 | url = https://www.csee.umbc.edu/courses/471/papers/turing.pdf| author-link = Alan Turing | doi=10.1093/mind/LIX.236.433}}
* {{cite journal | last1 = Saygin | first1 = A. P. | year = 2000 | title = Turing Test: 50 years later | journal = Minds and Machines | volume = 10 | issue = 4| pages = 463–518 | doi = 10.1023/A:1011288000451 | hdl = 11693/24987 | s2cid = 990084 | hdl-access = free }}
* [[Noah Wardrip-Fruin]] and Nick Montfort, eds. (2003). ''The New Media Reader''. Cambridge: MIT Press. {{ISBN|0-262-23227-8}}. "Lucasfilm's Habitat" pp.&nbsp;663–677.

==External links==
*[https://academic.oup.com/mind/article-pdf/LIX/236/433/9866119/433.pdf PDF with the full text of the paper]
*{{cite journal | citeseerx = 10.1.1.157.1592 | title = An analysis and review of the next 50 years | journal = Minds and Machines | pages = 2000 | year = 1999 | last1 = Saygin | first1 = Ayse Pinar | last2 = Cicekli | first2 = Ilyas | last3 = Akman | first3 = Varol }}

{{DEFAULTSORT:Computing Machinery And Intelligence}}
[[Category:1950 documents]]
[[Category:History of artificial intelligence]]
[[Category:Philosophy of artificial intelligence]]
[[Category:Artificial intelligence publications]]
[[Category:Alan Turing]]
[[Category:Computer science papers]]
[[Category:Cognitive science literature]]
[[Category:Works originally published in Mind (journal)]]