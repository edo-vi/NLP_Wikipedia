{{Short description|Observation that perception requires more computation than reasoning}}
'''Moravec's paradox''' is the observation in [[artificial intelligence]] and [[robotics]] that, contrary to traditional assumptions, [[reasoning]] requires very little computation, but [[Sensory processing#Sensorimotor system|sensorimotor]] and perception skills require enormous computational resources. The principle was articulated by [[Hans Moravec]], [[Rodney Brooks]], [[Marvin Minsky]] and others in the 1980s. Moravec wrote in 1988, "it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility".{{sfn|Moravec|1988|p= 15}}

Similarly, Minsky emphasized that the most difficult human skills to [[reverse engineer]] are those that are below the level of conscious awareness. "In general, we're least aware of what our minds do best", he wrote, and added "we're more aware of simple processes that don't work well than of complex ones that work flawlessly".{{sfn|Minsky|1986|p=2}} [[Steven Pinker]] wrote in 1994 that "the main lesson of thirty-five years of AI research is that the hard problems are easy and the easy problems are hard."{{sfn|Pinker|2007|p=190}}

By the 2020s, in accordance to [[Moore's law]], computers were hundreds of millions of times faster than in the 1970s, and the additional computer power was finally sufficient to begin to handle [[machine perception|perception]] and sensory skills, as Moravec had predicted in 1976.{{sfn|Moravec|1976}}  In 2017, leading [[machine learning]] researcher [[Andrew Ng]] presented a "highly imperfect rule of thumb", that "almost anything a typical human can do with less than one second of mental thought, we can probably now or in the near future automate using AI."{{sfn|Lee|2017}} There is currently no consensus as to which tasks AI tends to excel at.{{sfn|Brynjolfsson|Mitchell|2017}}

==The biological basis of human skills==
One possible explanation of the paradox, offered by Moravec, is based on [[evolution]]. All human skills are implemented biologically, using machinery designed by the process of [[natural selection]]. In the course of their evolution, natural selection has tended to preserve design improvements and optimizations. The older a skill is, the more time natural selection has had to improve the design. Abstract thought developed only very recently, and consequently, we should not expect its implementation to be particularly efficient.

As Moravec writes:
{{quote |Encoded in the large, highly evolved sensory and motor portions of the human brain is a billion years of experience about the nature of the world and how to survive in it. The deliberate process we call reasoning is, I believe, the thinnest veneer of human thought, effective only because it is supported by this much older and much more powerful, though usually unconscious, sensorimotor knowledge. We are all prodigious olympians in perceptual and motor areas, so good that we make the difficult look easy. Abstract thought, though, is a new trick, perhaps less than 100 thousand years old. We have not yet mastered it. It is not all that intrinsically difficult; it just seems so when we do it.{{Sfn |Moravec|1988|pp=15–16}}}}

A compact way to express this argument would be:
* We should expect the difficulty of reverse-engineering any human skill to be roughly proportional to the amount of time that skill has been evolving in animals.
* The oldest human skills are largely unconscious and so appear to us to be effortless.
* Therefore, we should expect skills that appear effortless to be difficult to reverse-engineer, but skills that require effort may not necessarily be difficult to engineer at all.

Some examples of skills that have been evolving for millions of years: recognizing a face, moving around in space, judging people's motivations, catching a ball, recognizing a voice, setting appropriate goals, paying attention to things that are interesting; anything to do with perception, attention, visualization, motor skills, social skills and so on.

Some examples of skills that have appeared more recently: mathematics, engineering, games, logic and scientific reasoning. These are hard for us because they are not what our bodies and brains were primarily evolved to do. These are skills and techniques that were acquired recently, in historical time, and have had at most a few thousand years to be refined, mostly by cultural evolution.

==Historical influence on artificial intelligence==
In the early days of artificial intelligence research, leading researchers often predicted that they would be able to create thinking machines in just a few decades (see [[history of artificial intelligence#Optimism|history of artificial intelligence]]). Their optimism stemmed in part from the fact that they had been successful at writing programs that used logic, solved algebra and geometry problems and played games like checkers and chess. Logic and [[algebra]] are difficult for people and are considered a sign of intelligence. Many prominent researchers{{efn|[[Anthony Zador]] wrote in 2019: 
"Herbert Simon, a pioneer of artificial intelligence (AI), famously predicted in 1965 that “machines will be capable, within twenty years, of doing any work a man can do” &mdash; to achieve [human-level] general AI."{{sfn|Zador|2019}}}} assumed that, having (almost) solved the "hard" problems, the "easy" problems of [[computer vision|vision]] and [[commonsense reasoning]] would soon fall into place. They were wrong (see also [[AI winter]]), and one reason is that these problems are not easy at all, but incredibly difficult. The fact that they had solved problems like logic and algebra was irrelevant, because these problems are extremely easy for machines to solve.{{efn|These are not the only reasons that their predictions did not come true: see {{section link|History of artificial intelligence|The problems}}.}}

[[Rodney Brooks]] explains that, according to early AI research, [[intelligence]] was "best characterized as the things that highly educated male scientists found challenging", such as chess, [[symbolic integration]], proving [[math|mathematical]] [[theorem]]s and solving complicated word algebra problems. "The things that children of four or five years could do effortlessly, such as visually distinguishing between a coffee cup and a chair, or walking around on two legs, or finding their way from their bedroom to the living room were not thought of as activities requiring intelligence."<ref name=Brooks2002>{{Harvtxt|Brooks|2002}}, quoted in {{Harvtxt|McCorduck|2004|p= 456}}</ref>

In the 1980s, this would lead Brooks to pursue a new direction in [[artificial intelligence]] and [[robotics]] research. He decided to build intelligent machines that had "No cognition. Just sensing and action. That is all I would build and completely leave out what traditionally was thought of as the ''intelligence'' of artificial intelligence."<ref name=Brooks2002/> He called this new direction "[[Nouvelle AI]]".{{sfn|Brooks|1986}}

Similarly, successful 21st century AI applications don't simulate step-by-step "intelligent" problem solving, they simulate the fast, "intuitive" judgements people use to instantly and automatically recognize patterns and anomalies.{{Citation needed|reason=Statement is very brought and does not give any example|date=April 2023}}

==Reception==
Linguist and cognitive scientist [[Steven Pinker]] considers this the main lesson uncovered by AI researchers. In his 1994 book ''[[The Language Instinct]]'', he wrote:
 
{{quote |The main lesson of thirty-five years of AI research is that the hard problems are easy and the easy problems are hard. The mental abilities of a four-year-old that we take for granted – recognizing a face, lifting a pencil, walking across a room, answering a question – in fact solve some of the hardest engineering problems ever conceived... As the new generation of intelligent devices appears, it will be the stock analysts and petrochemical engineers and parole board members who are in danger of being replaced by machines. The gardeners, receptionists, and cooks are secure in their jobs for decades to come.{{sfn|Pinker|2007|pp= 190–91}}}}

==See also==
*[[AI effect]]
*[[Embodied cognition]]
* [[History of artificial intelligence]]
* [[Subsumption architecture]]

==Notes==
{{notelist}}

==References==
{{Reflist |32em}}

==Bibliography==
{{Refbegin}}
* {{Citation | first = Rodney | last = Brooks | year = 1986 | title = Intelligence Without Representation | publisher=MIT Artificial Intelligence Laboratory | author-link=Rodney Brooks|url = http://people.csail.mit.edu/brooks/papers/representation.ps.Z }}
* {{Citation | first = Rodney | last = Brooks | year = 2002 | title = Flesh and Machines | publisher=Pantheon Books | author-link=Rodney Brooks }}
* {{cite journal|last1=Brynjolfsson|first1=Erik|last2=Mitchell|first2=Tom|date=22 December 2017|title=What can machine learning do? Workforce implications|language=en|pages=1530–1534|journal=Science|volume=358 |issue=6370 |url=https://www.science.org/doi/10.1126/science.aap8062|access-date=7 May 2018|bibcode=2017Sci...358.1530B|doi=10.1126/science.aap8062}}
* {{cite news|last=Lee|first=Amanda|date=14 June 2017|title=Will your job still exist in 10 years when the robots arrive?|language=en|work=[[South China Morning Post]]|url=http://www.scmp.com/tech/innovation/article/2098164/robots-are-coming-here-are-some-jobs-wont-exist-10-years|access-date=7 May 2018}}
* {{Citation | first = Marvin | last = Minsky | title = The Society of Mind | publisher = Simon and Schuster | year = 1986 | author-link=Marvin Minsky | page=29| title-link = The Society of Mind }}
* {{Citation | last = Moravec | first = Hans | title = The Role of Raw Power in Intelligence | url = http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html | year = 1976 | author-link = Hans Moravec | access-date = 16 October 2008 | archive-url = https://web.archive.org/web/20160303232511/http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html | archive-date = 3 March 2016 | url-status = dead }}
* {{Citation | first = Hans | last = Moravec | year = 1988 | title = Mind Children | publisher = Harvard University Press | author-link =Hans Moravec}}
* {{McCorduck 2004}}, p.&nbsp;456.
* {{Citation | last=Pinker | first=Steven | author-link=Steven Pinker | title=The Language Instinct | date=September 4, 2007 | orig-year=1994 | publisher=Harper | series = Perennial Modern Classics | isbn=978-0-06-133646-1| title-link=The Language Instinct }}
* {{cite journal |last=Zador |first=Anthony |date=2019-08-21 |title=A critique of pure learning and what artificial neural networks can learn from animal brains |journal= Nature Communications|volume=10 |issue=1 |pages=3770 |doi=10.1038/s41467-019-11786-6 |pmid=31434893 |pmc=6704116 |bibcode=2019NatCo..10.3770Z }}
{{Refend}}

==External links==
* [https://www.explainxkcd.com/wiki/index.php/1425:_Tasks Explanation] of the [https://xkcd.com/1425/ XKCD comic] about Moravec's paradox

{{DEFAULTSORT:Moravec's Paradox}}
[[Category:Philosophy of artificial intelligence]]
[[Category:Paradoxes]]