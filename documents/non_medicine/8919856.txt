{{short description|Overview of Hubert Dreyfus's views on artificial intelligence}}
[[File:CoverOfWhatComputersCantDo.jpg|thumb|Book cover of the 1979 paperback edition]]
[[Hubert Dreyfus]] was a critic of [[artificial intelligence]] research. In a series of papers and books, including '''''Alchemy and AI''''' [[#{{harvid|Dreyfus|1965}}|(1965)]], '''''What Computers Can't Do''''' ([[#{{harvid|Dreyfus|1972}}|1972]]; [[#{{harvid|Dreyfus|1979}}|1979]]; [[#{{harvid|Dreyfus|1992}}|1992]]) and '''''Mind over Machine''''' [[#{{harvid|Dreyfus|Dreyfus|1986}}|(1986)]], he presented a pessimistic assessment of AI's progress and a critique of the philosophical foundations of the field. Dreyfus' objections are discussed in most introductions to the [[philosophy of artificial intelligence]], including {{Harvtxt|Russell|Norvig|2021}}, a standard AI textbook, and in {{Harvtxt|Fearn|2007}}, a survey of contemporary philosophy.<ref>Dreyfus was one of the only non-computer scientists asked for a comment in IEEE's survey of AI's greatest controversies. {{Harv|Hearst et al.|2000}}</ref>

Dreyfus argued that human intelligence and expertise depend primarily on unconscious processes rather than conscious [[physical symbol system|symbolic]] manipulation, and that these unconscious skills can never be fully captured in formal rules. His critique was based on the insights of modern [[continental philosophy|continental philosopher]]s such as [[Merleau-Ponty]] and [[Heidegger]], and was directed at the first wave of AI research which used high level [[physical symbol system|formal symbols]] to represent reality and tried to reduce intelligence to symbol manipulation.

When Dreyfus' ideas were first introduced in the mid-1960s, they were met with ridicule and outright hostility.{{sfn|McCorduck|2004|pp=211–243}}{{sfn|Crevier|1993|pp=120–132}} By the 1980s, however, many of his perspectives were rediscovered by researchers working in [[robotics]] and the new field of [[connectionism]]—approaches now called "[[Artificial intelligence#Sub-symbolic|sub-symbolic]]" because they eschew early AI research's emphasis on high level symbols. In the 21st century, [[AI#Statistical learning|statistics-based]] approaches to [[machine learning]] simulate the way that the brain uses unconscious process to perceive, notice anomalies and make quick judgements. These techniques are highly successful and are currently widely used in both industry and academia.  Historian and AI researcher [[Daniel Crevier]] writes: "time has proven the accuracy and perceptiveness of some of Dreyfus's comments."{{sfn|Crevier|1993|p=125}} Dreyfus said in 2007, "I figure I won and it's over—they've given up."<ref>Quoted in {{Harvnb|Fearn|2007|p=51}}</ref>

== Dreyfus' critique ==
=== The grandiose promises of artificial intelligence ===

In ''Alchemy and AI'' [[#{{harvid|Dreyfus|1965}}|(1965)]] and ''What Computers Can't Do'' [[#{{harvid|Dreyfus|1972}}|(1972)]], [[Hubert Dreyfus|Dreyfus]] summarized the [[history of artificial intelligence]] and ridiculed the unbridled optimism that permeated the field. For example, [[Herbert A. Simon]], following the success of his program [[General Problem Solver]] [[#{{harvid|Newell|Simon|1963}}|(1957)]], predicted that by 1967:{{sfn|Newell|Simon|1963}}
# A computer would be world champion in chess.
# A computer would discover and prove an important new mathematical theorem.
# Most theories in psychology will take the form of computer programs.
The press reported these predictions in glowing reports of the imminent arrival of machine intelligence.

Dreyfus felt that this optimism was unwarranted and based on false assumptions about the nature of human intelligence. Pamela McCorduck explains Dreyfus position:
<blockquote>A great misunderstanding accounts for public confusion about thinking machines, a misunderstanding perpetrated by the unrealistic claims researchers in AI have been making, claims that thinking machines are already here, or at any rate, just around the corner.{{sfn|McCorduck|2004|p=212}}</blockquote>

These predictions were based on the success of an "information processing" model of the mind, articulated by Newell and Simon in their [[physical symbol systems hypothesis]], and later expanded into a philosophical position known as [[computationalism]] by philosophers such as [[Jerry Fodor]] and [[Hilary Putnam]].{{sfn|Horst|2005}} Believing that they had successfully simulated the essential process of human thought with simple programs, it seemed a short step to producing fully intelligent machines. However, Dreyfus argued that philosophy, especially [[20th-century philosophy]], had discovered serious problems with this information processing viewpoint. The mind, according to modern philosophy, is nothing like a digital computer.{{sfn|McCorduck|2004|p=212}}

=== Dreyfus' four assumptions of artificial intelligence research ===

In ''Alchemy and AI'' and ''What Computers Can't Do'', Dreyfus identified four philosophical assumptions that supported the faith of early AI researchers that human intelligence depended on the manipulation of symbols.{{sfn|McCorduck|2004|p=211}} "In each case," Dreyfus writes, "the assumption is taken by workers in [AI] as an axiom, guaranteeing results, whereas it is, in fact, one hypothesis among others, to be tested by the success of such work."{{sfn|Dreyfus|1979|p=157}}

;The biological assumption: ''The brain processes information in discrete operations by way of some biological equivalent of on/off switches.''

In the early days of research into [[neurology]], scientists realized that [[neuron]]s fire in all-or-nothing pulses. Several researchers, such as [[Walter Pitts]] and [[Warren Sturgis McCulloch|Warren McCulloch]], argued that neurons functioned similar to the way [[Boolean logic]] gates operate, and so could be imitated by electronic circuitry at the level of the neuron.<ref>{{Harvnb|McCorduck|2004|pp=51–57, 88–94}}; {{Harvnb|Crevier|1993|p=30}}; {{Harvnb|Russell|Norvig|2021|p=17}}</ref>
When digital computers became widely used in the early 50s, this argument was extended to suggest that the brain was a vast [[physical symbol system]], manipulating the binary symbols of zero and one. Dreyfus was able to refute the biological assumption by citing research in [[neurology]] that suggested that the action and timing of neuron firing had analog components.{{sfn|Dreyfus|1992|pp=158–62}} But Daniel Crevier observes that "few still held that belief in the early 1970s, and nobody argued against Dreyfus" about the biological assumption.{{sfn|Crevier|1993|p=126}}

;The psychological assumption: ''The mind can be viewed as a device operating on bits of information according to formal rules.''

He refuted this assumption by showing that much of what we "know" about the world consists of complex ''attitudes'' or ''tendencies'' that make us lean towards one interpretation over another. He argued that, even when we use explicit symbols, we are using them against an unconscious background of [[commonsense knowledge]] and that without this background our symbols cease to mean anything. This background, in Dreyfus' view, was not implemented in individual brains as explicit individual symbols with explicit individual meanings.

;The epistemological assumption: ''All knowledge can be formalized.''

This concerns the philosophical issue of [[epistemology]], or the study of [[knowledge]].  Even if we agree that the psychological assumption is false, AI researchers could still argue (as AI founder [[John McCarthy (computer scientist)|John McCarthy]] has) that it is possible for a symbol processing machine to represent all knowledge, regardless of whether human beings represent knowledge the same way. Dreyfus argued that there is no justification for this assumption, since so much of human knowledge is not symbolic.

;The ontological assumption: ''The world consists of independent facts that can be represented by independent symbols''

[[Hubert Dreyfus|Dreyfus]] also identified a subtler assumption about the world. AI researchers (and futurists and science fiction writers) often assume that there is no limit to formal, scientific knowledge, because they assume that any phenomenon in the universe can be described by symbols or scientific theories. This assumes that everything that ''exists'' can be understood as objects, properties of objects, classes of objects, relations of objects, and so on: precisely those things that can be described by logic, language and mathematics. The study of being or existence is called [[ontology]], and so [[Hubert Dreyfus|Dreyfus]] calls this the ontological assumption. If this is false, then it raises doubts about what we can ultimately know and what intelligent machines will ultimately be able to help us to do.

=== Knowing-how vs. knowing-that: the primacy of intuition ===

In ''Mind Over Machine'' [[#{{harvid|Dreyfus|Dreyfus|1986}}|(1986)]], written during the heyday of [[expert systems]], Dreyfus analyzed the difference between human expertise and the programs that claimed to capture it. This expanded on ideas from ''What Computers Can't Do'', where he had made a similar argument criticizing the "[[Computational cognition|cognitive simulation]]" school of AI research practiced by [[Allen Newell]] and [[Herbert A. Simon]] in the 1960s.

Dreyfus argued that human problem solving and expertise depend on our background sense of the context, of what is important and interesting given the situation, rather than on the process of searching through combinations of possibilities to find what we need. Dreyfus would describe it in 1986 as the difference between "knowing-that" and "knowing-how", based on [[Heidegger]]'s distinction of [[present-at-hand]] and [[ready-to-hand]].<ref>{{Harvnb|Dreyfus|Dreyfus|1986}} and see [https://www.jstor.org/stable/3823297  From Socrates to Expert Systems]. The "knowing-how"/"knowing-that" terminology was introduced in the 1950s by philosopher [[Gilbert Ryle]].</ref>

Knowing-that is our conscious, step-by-step problem solving abilities. We use these skills when we encounter a difficult problem that requires us to stop, step back and search through ideas one at time. At moments like this, the ideas become very precise and simple: they become context free symbols, which we manipulate using logic and language. These are the skills that [[Allen Newell|Newell]] and [[Herbert A. Simon|Simon]] had demonstrated with both psychological experiments and computer programs. Dreyfus agreed that their programs adequately imitated the skills he calls "knowing-that."

Knowing-how, on the other hand, is the way we deal with things normally. We take actions without using conscious symbolic reasoning at all, as when we recognize a face, drive ourselves to work or find the right thing to say. We seem to simply jump to the appropriate response, without considering any alternatives. This is the essence of expertise, Dreyfus argued: when our intuitions have been trained to the point that we forget the rules and simply "size up the situation" and react.

The human sense of the situation, according to Dreyfus, is based on our goals, our bodies and our culture—all of our unconscious intuitions, attitudes and knowledge about the world. This “context” or "background" (related to [[Heidegger]]'s [[Dasein]]) is a form of knowledge that is not stored in our brains symbolically, but intuitively in some way. It affects what we notice and what we don't notice, what we expect and what possibilities we don't consider: we discriminate between what is essential and inessential. The things that are inessential are relegated to our "fringe consciousness" (borrowing a phrase from [[William James]]): the millions of things we're aware of, but we're not really thinking about right now. 

[[Hubert Dreyfus|Dreyfus]] does not believe that AI programs, as they were implemented in the 70s and 80s, could capture this "background" or do the kind of fast problem solving that it allows. He argued that our unconscious knowledge could ''never'' be captured symbolically. If AI could not find a way to address these issues, then it was doomed to failure, an exercise in "tree climbing with one's eyes on the moon."{{sfn|Dreyfus|1992|p=119}}

== History ==

Dreyfus began to formulate his critique in the early 1960s while he was a professor at [[MIT]], then a hotbed of artificial intelligence research. His first publication on the subject is a half-page objection to a talk given by [[Herbert A. Simon]] in the spring of 1961.{{sfn|McCorduck|2004|p=225}} Dreyfus was especially bothered, as a philosopher, that AI researchers seemed to believe they were on the verge of solving many long standing philosophical problems within a few years, using computers.

=== "Alchemy and AI" ===
In 1965, Dreyfus was hired (with his brother [[Stuart Dreyfus]]' help) by [[Paul Armer]] to spend the summer at [[RAND Corporation]]'s Santa Monica facility, where he would write "Alchemy and AI", the first salvo of his attack. Armer had thought he was hiring an impartial critic and was surprised when Dreyfus produced a scathing paper intended to demolish the foundations of the field.  (Armer stated he was unaware of Dreyfus' previous publication.) Armer delayed publishing it, but ultimately realized that "just because it came to a conclusion you didn't like was no reason not to publish it."<ref>Paul Armer, quoted in {{Harvtxt|McCorduck|2004|p=226}}</ref> It finally came out as RAND Memo and soon became a best seller.{{sfn|McCorduck|2004|p=225-227}}

The paper flatly ridiculed AI research, comparing it to [[alchemy]]: a misguided attempt to change metals to gold based on a theoretical foundation that was no more than mythology and wishful thinking.{{sfn|McCorduck|2004|p=238}} It ridiculed the grandiose predictions of leading AI researchers, predicting that there were limits beyond which AI would not progress and intimating that those limits would be reached soon.{{sfn|McCorduck|2004|p=230}}

=== Reaction ===
The paper "caused an uproar", according to Pamela McCorduck.{{sfn|McCorduck|2004|pp=227–228}} The AI community's response was derisive and personal. [[Seymour Papert]] dismissed one third of the paper as "gossip" and claimed that every quotation was deliberately taken out of context.{{sfn|McCorduck|2004|p=228}} [[Herbert A. Simon]] accused Dreyfus of playing "politics" so that he could attach the prestigious RAND name to his ideas. Simon said, "what I resent about this was the RAND name attached to that garbage".<ref>Quoted in {{Harvtxt|McCorduck|2004|p=226}}</ref>

Dreyfus, who taught at [[Massachusetts Institute of Technology|MIT]], remembers that his colleagues working in AI  "dared not be seen having lunch with me."<ref>Quoted in {{Harvnb|Crevier|1993|p=122}}</ref> [[Joseph Weizenbaum]], the author of [[ELIZA]], felt his colleagues' treatment of [[Hubert Dreyfus|Dreyfus]] was unprofessional and childish. Although he was an outspoken critic of Dreyfus' positions, he recalls "I became the only member of the AI community to be seen eating lunch with Dreyfus. And I deliberately made it plain that theirs was not the way to treat a human being."<ref>[[Joseph Weizenbaum]], quoted in {{Harvnb|Crevier|1993|p=123}}.</ref>

The paper was the subject of a short in ''[[The New Yorker]]'' magazine on June 11, 1966. The piece mentioned Dreyfus' contention that, while computers may be able to play checkers, no computer could yet play a decent game of chess. It reported with wry humor (as Dreyfus had) about the victory of a ten-year-old over the leading chess program,  with "even more than its usual smugness."{{sfn|McCorduck|2004|p=230}}

In hope of restoring AI's reputation, [[Seymour Papert]] arranged a chess match between Dreyfus and [[Richard Greenblatt (programmer)|Richard Greenblatt]]'s [[Mac Hack]] program. Dreyfus lost, much to Papert's satisfaction.{{sfn|McCorduck|2004|p=230-232}} An [[Association for Computing Machinery]] bulletin<ref>The bulletin was for the Special Interest Group in Artificial Intelligence. (ACM SIGART).</ref> used the headline:
: "A Ten Year Old Can Beat the Machine— Dreyfus: ''But the Machine Can Beat Dreyfus''"<ref>Quoted in {{Harvtxt|McCorduck|2004|p=232}}</ref>
Dreyfus complained in print that he hadn't said a computer will ''never'' play chess, to which [[Herbert A. Simon]] replied: "You should recognize that some of those who are bitten by your sharp-toothed prose are likely, in their human weakness, to bite back ... may I be so bold as to suggest that you could well begin the cooling---a recovery of your sense of humor being a good first step."{{sfn|McCorduck|2004|p=233}}

=== Vindicated ===
By the early 1990s several of Dreyfus' radical opinions had become mainstream.

'''Failed predictions'''. As Dreyfus had foreseen, the grandiose predictions of early AI researchers failed to come true. Fully intelligent machines (now known as "[[Artificial general intelligence|strong AI]]") did not appear in the mid-1970s as predicted. [[HAL 9000]] (whose capabilities for natural language, perception and problem solving were based on the advice and opinions of [[Marvin Minsky]]) did not appear in the year 2001. "AI researchers", writes Nicolas Fearn, "clearly have some explaining to do."{{sfn|Fearn|2007|p=40}} Today researchers are far more reluctant to make the kind of predictions that were made in the early days. (Although some futurists, such as [[Ray Kurzweil]], are still given to the same kind of optimism.)

'''The biological assumption''', although common in the forties and early fifties, was no longer assumed by most AI researchers by the time Dreyfus published ''What Computers Can't Do''.{{sfn|Crevier|1993|p=126}} Although many still argue that it is essential to reverse-engineer the brain by simulating the action of neurons (such as [[Ray Kurzweil]]{{sfn|Kurzweil|2005}} or [[Jeff Hawkins]]{{sfn|Hawkins|Blakeslee|2005}}), they don't assume that neurons are essentially digital, but rather that the action of analog neurons can be simulated by digital machines to a reasonable level of accuracy.{{sfn|Kurzweil|2005}} ([[Alan Turing]] had made this same observation as early as 1950.)<ref>{{Harvnb|Turing|1950}} under "(7) Argument from Continuity in the Nervous System."</ref>

'''The psychological assumption''' and '''unconscious skills'''. Many AI researchers have come to agree that human reasoning does not consist primarily of high-level symbol manipulation. In fact, since Dreyfus first published his critiques in the 60s, AI research in general has moved away from [[symbolic AI|high level symbol manipulation]], towards new models that are intended to capture more of our ''unconscious'' reasoning. [[Daniel Crevier]] writes that by 1993, unlike 1965, AI researchers "no longer made the psychological assumption",{{sfn|Crevier|1993|p=126}} and had continued forward without it. 

In the 1980s, these new "[[sub-symbolic]]" approaches included: 
* [[Computational intelligence]] paradigms, such as [[neural net]]s, [[evolutionary algorithm]]s and so on are mostly directed at simulated unconscious reasoning.  Dreyfus himself agrees that these sub-symbolic methods can capture the kind of "tendencies" and "attitudes" that he considers essential for intelligence and expertise.{{sfn|Dreyfus|1992|pp=xiv-xvi}}
* Research into [[commonsense knowledge]] has focused on reproducing the "background" or context of knowledge.
* [[Robotics]] researchers like [[Hans Moravec]] and [[Rodney Brooks]] were among the first to realize that unconscious skills would prove to be the most difficult to reverse engineer. (See [[Moravec's paradox]].)  Brooks would spearhead a movement in the late 80s that took direct aim at the use of high-level symbols, called [[Nouvelle AI]]. The [[situated]] movement in [[robotics]] research attempts to capture our unconscious skills at perception and attention.<ref>See {{Harvnb|Brooks|1990}} or {{Harvnb|Moravec|1988}}</ref>

In the 1990s and the early decades of the 21st century, [[AI#Statistical learning|statistics-based approaches to machine learning]] used techniques related to economics and statistics to allow machines to "guess" &ndash; to make inexact, probabilistic decisions and predictions based on experience and learning. These programs simulate the way our unconscious instincts are able to perceive, notice anomalies and make quick judgements, similar to what Dreyfus called "sizing up the situation and reacting", but here the "situation" consists of vast amounts of numerical data. These techniques are highly successful and are currently widely used in both industry and academia.

This research has gone forward without any direct connection to Dreyfus' work.{{sfn|McCorduck|2004|p=236}}

'''Knowing-how and knowing-that'''. Research in psychology and economics has been able to show that Dreyfus' (and Heidegger's) speculation about the nature of human problem solving was essentially correct. [[Daniel Kahnemann]] and [[Amos Tversky]] collected a vast amount of hard evidence that human beings use two very different methods to solve problems, which they named "system 1" and "system 2". System one, also known as the  [[adaptive unconscious]], is fast, intuitive and unconscious. System 2 is slow, logical and deliberate. Their research was collected in the book ''[[Thinking, Fast and Slow]]'',{{sfn|Kahneman|2011}} and inspired [[Malcolm Gladwell]]'s popular book ''[[Blink (book)|Blink]]''.{{sfn|Gladwell|2005}} As with AI, this research was entirely independent of both Dreyfus and Heidegger.{{sfn|McCorduck|2004|p=236}}

===Ignored===
Although clearly AI research has come to agree with Dreyfus, McCorduck claimed that "my impression is that this progress has taken place piecemeal and in response to tough given problems, and owes nothing to Dreyfus."{{sfn|McCorduck|2004|p=236}}

The AI community, with a few exceptions, chose not to respond to Dreyfus directly. "He's too silly to take seriously" a researcher told Pamela McCorduck.{{sfn|McCorduck|2004|p= 233}} [[Marvin Minsky]] said of Dreyfus (and the other critiques coming from [[philosophy]]) that "they misunderstand, and should be ignored."{{sfn|Crevier|1993|p=143}} When Dreyfus expanded ''Alchemy and AI'' to book length and published it as ''What Computers Can't Do'' in 1972, no one from the AI community chose to respond (with the exception of a few critical reviews). McCorduck asks "If Dreyfus is so wrong-headed, why haven't the artificial intelligence people made more effort to contradict him?"{{sfn|McCorduck|2004|p=233}}

Part of the problem was the ''kind'' of philosophy that Dreyfus used in his critique. Dreyfus was an expert in [[continental philosophy|modern European philosophers]] (like [[Heidegger]] and [[Merleau-Ponty]]).{{sfn|McCorduck|2004|p=213}} AI researchers of the 1960s, by contrast, based their understanding of the human mind on engineering principles and efficient problem solving techniques related to [[management science]]. On a fundamental level, they spoke a different language. [[Edward Feigenbaum]] complained, "What does he offer us? [[Phenomenology (philosophy)|Phenomenology]]! That ball of fluff. That cotton candy!"<ref>Quoted in {{Harvtxt|McCorduck|2004|pp=229–230}}</ref> In 1965, there was simply too huge a gap between European philosophy and [[artificial intelligence]], a gap that has since been filled by [[cognitive science]], [[connectionism]] and [[robotics]] research. It would take many years before artificial intelligence researchers were able to address the issues that were important to continental philosophy, such as [[situated]]ness, [[Embodied cognition|embodiment]], [[perception]] and [[gestaltism|gestalt]].

Another problem was that he claimed (or seemed to claim) that AI would ''never'' be able to capture the human ability to understand context, situation or purpose in the form of rules. But (as [[Peter Norvig]] and [[Stuart J. Russell|Stuart Russell]] would later explain), an argument of this form cannot be won: just because one cannot imagine formal rules that govern human intelligence and expertise, this does not mean that no such rules exist. They quote [[Alan Turing]]'s answer to all arguments similar to Dreyfus's:<blockquote>"we cannot so easily convince ourselves of the absence of complete laws of behaviour ... The only way we know of for finding such laws is scientific observation, and we certainly know of no circumstances under which we could say, 'We have searched enough. There are no such laws.'"{{sfn|Turing|1950|loc=under "(8) The Argument from the Informality of Behavior"}}</blockquote>Dreyfus did not anticipate that AI researchers would realize their mistake and begin to work towards new solutions, moving away from the symbolic methods that Dreyfus criticized. In 1965, he did not imagine that such programs would one day be created, so he claimed AI was impossible. In 1965, AI researchers did not imagine that such programs were necessary, so they claimed AI was almost complete. Both were wrong.

A more serious issue was the impression that Dreyfus' critique was incorrigibly hostile. McCorduck wrote, "His derisiveness has been so provoking that he has estranged anyone he might have enlightened. And that's a pity."{{sfn|McCorduck|2004|p=236}} Daniel Crevier stated that "time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier."{{sfn|Crevier|1993|p=125}}

==See also==
* [[Adaptive unconscious]]
* [[Church–Turing thesis]]
* [[Computer chess]]
* [[Hubert Dreyfus]]
* [[Philosophy of artificial intelligence]]

== Notes ==
{{reflist|30em}}

== References ==
* {{Citation 
| last=Brooks | first=Rodney | author-link=Rodney Brooks 
| year =1990 
| title = Elephants Don't Play Chess 
| journal = Robotics and Autonomous Systems | volume=6 | issue=1–2 | pages=3–15  
| url=http://people.csail.mit.edu/brooks/papers/elephants.pdf | access-date=30 August 2007 
| doi=10.1016/S0921-8890(05)80025-9
| citeseerx=10.1.1.588.7539 }}
* {{Crevier 1993}}
* {{Citation 
| last=Dreyfus | first=Hubert | author-link = Hubert Dreyfus 
| year =1965 
| title = Alchemy and AI
| publisher = [[RAND Corporation]] 
}}
* {{Citation | last=Dreyfus | first=Hubert | author-link=Hubert Dreyfus | year=1972 | title=What Computers Can't Do | publisher=MIT Press | location=New York | isbn=978-0-06-090613-9 | url=https://archive.org/details/whatcomputerscan00hube }}
* {{Citation 
| last=Dreyfus | first=Hubert  | author-link = Hubert Dreyfus  
| year =1979 
| title = What Computers Can't Do 
| publisher = MIT Press | location = New York
| isbn=978-0-06-090624-5 
}}.
* {{Citation 
| last1=Dreyfus | first1=Hubert  | author-link = Hubert Dreyfus  
| last2 = Dreyfus | first2 = Stuart | authorlink2 = Stuart Dreyfus
| year = 1986 
| title = Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer 
| publisher = Blackwell | location = Oxford, U.K.
}}.
* {{citation
| last=Dreyfus | first=Hubert | author-link = Hubert Dreyfus
| year =1992
| title = What Computers ''Still'' Can't Do
| publisher = MIT Press | location = New York
| isbn=978-0-262-54067-4
}}
* {{Citation 
| last=Fearn | first = Nicholas 
| year =2007 
| title= The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers 
| publisher = Grove Press 
| location=New York
| isbn = 9780802143471 
| url=https://books.google.com/books?id=kXBsBnF_DVsC&q=Dreyfus
}}.
* {{Citation 
| last=Gladwell | first=Malcolm |author-link= Malcolm Gladwell
| year=2005
| title=Blink: The Power of Thinking Without Thinking
| location=Boston | publisher=Little, Brown  
| isbn= 978-0-316-17232-5
| title-link=Blink (book) }}.
* {{Citation
| last1=Hawkins | first1=Jeff | author-link=Jeff Hawkins
| last2=Blakeslee | first2=Sandra
| year=2005
| title=On Intelligence
| publisher=Owl Books | location=New York, NY
| isbn=978-0-8050-7853-4
| title-link=On Intelligence }}.
* {{Citation | ref ={{harvid|Hearst et al.|2000}}
| last1 = Hearst | first1 = Marti A.
| last2 = Hirsh | first2 = Haym
| date = January–February 2000 
| title=AI's Greatest Trends and Controversies
| journal = IEEE Intelligent Systems | volume = 15 | pages=8–17
| doi=10.1109/5254.820322 | issue = 1
| last3 = Bundy
| first3 = A.
| last4 = Berliner
| first4 = H.
| last5 = Feigenbaum
| first5 = E.A.
| last6 = Buchanan
| first6 = B.G.
| last7 = Selfridge
| first7 = O.
| last8 = Michie
| first8 = D.
| last9 = Nilsson
| first9 = N.
| postscript = .

}}
* {{Citation 
| last=Horst | first= Steven 
| contribution =The Computational Theory of Mind 
| title= The Stanford Encyclopedia of Philosophy 
| date = Fall 2005 
| editor-first = Edward N. | editor-last = Zalta 
| url = http://plato.stanford.edu/archives/fall2005/entries/computational-mind/
}}.
* {{Citation 
| title          = Thinking, Fast and Slow
| first          = Daniel | last = Kahneman | author-link = Daniel Kahneman
| year           = 2011
| publisher      = [[Farrar, Straus and Giroux]]
| isbn           = 978-0374275631
| oclc           = 706020998
}}
* {{Citation
| last=Kurzweil | first = Ray | author-link = Ray Kurzweil
| title = The Singularity is Near 
| year = 2005 
| publisher = Viking Press 
| location = New York 
| isbn=978-0-670-03384-3
| title-link = The Singularity is Near }}.
* {{McCorduck 2004}}
* {{Citation | last=Moravec | first=Hans | author-link=Hans Moravec
| year = 1988 
| title = Mind Children
| publisher = Harvard University Press
| isbn=978-0-674-57616-2 
}}.
* {{Citation 
| last1=Newell | first1=Allen | author-link=Allen Newell 
| last2 = Simon | first2=H. A.
| year = 1963 
| contribution=GPS: A Program that Simulates Human Thought| title=Computers and Thought 
| editor-last= Feigenbaum | editor-first= E.A. 
|editor2-last= Feldman |editor2-first= J. 
|publisher= McGraw-Hill| authorlink2 = Herbert A. Simon|location= New York }}
* {{Cite book
| first1 = Stuart J. | last1 = Russell | author1-link = Stuart J. Russell
| first2 = Peter.    | last2 = Norvig  | author2-link = Peter Norvig
| title=[[Artificial Intelligence: A Modern Approach]]
| year = 2021
| edition = 4th 
| isbn = 9780134610993 
| lccn = 20190474
| publisher = Pearson | location = Hoboken
}}
* {{Turing 1950}}.

{{DEFAULTSORT:Dreyfus views on artificial intelligence, Hubert}}
[[Category:Philosophy of artificial intelligence]]