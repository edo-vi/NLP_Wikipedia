{{Short description|Ethical problems related to robots}}
{{Multiple issues|
{{more citations needed|date=June 2017}}
{{Citation style|date=August 2021}}
}}
'''Robot ethics''', sometimes known as "'''roboethics'''", concerns ethical problems that occur with robots, such as whether robots pose a threat to humans in the long or short run, whether some ''uses'' of robots are problematic (such as in healthcare or as '[[Lethal autonomous weapon|killer robots]]' in war), and how robots should be designed such that they act 'ethically' (this last concern is also called [[machine ethics]]). Alternatively, roboethics refers specifically to the ethics of ''human behavior'' towards robots, as robots become increasingly advanced.<ref>{{Citation|last1=Veruggio|first1=Gianmarco|title=Roboethics: Social and Ethical Implications of Robotics|date=2008|work=Springer Handbook of Robotics|pages=1499–1524|editor-last=Siciliano|editor-first=Bruno|publisher=Springer Berlin Heidelberg|language=en|doi=10.1007/978-3-540-30301-5_65|isbn=9783540303015|last2=Operto|first2=Fiorella|editor2-last=Khatib|editor2-first=Oussama}}</ref> Robot ethics is a sub-field of ethics of technology, specifically information technology, and it has close links to legal as well as socio-economic concerns.  Researchers from diverse areas are beginning to tackle ethical questions about creating robotic technology and implementing it in societies, in a way that will still ensure the safety of the human race.<ref>{{Cite web|url=http://www.ieee-ras.org/robot-ethics|title=Robot Ethics|website=IEEE Robotics and Automation Society|language=en-gb|access-date=2017-06-26}}</ref>

While the issues are as old as the word ''robot'', serious academic discussions started around the year 2000. Robot ethics requires the combined commitment of experts of several disciplines, who have to adjust laws and regulations to the problems resulting from the scientific and technological achievements in Robotics and AI. The main fields involved in robot ethics are: [[robotics]], [[computer science]], [[artificial intelligence]], [[philosophy]], [[ethics]], [[theology]], [[biology]], [[physiology]], [[cognitive science]], [[neuroscience]]s, [[law]], [[sociology]], [[psychology]], and [[industrial design]].<ref>{{Cite web |title=Robot Ethics - IEEE Robotics and Automation Society - IEEE Robotics and Automation Society |url=https://www.ieee-ras.org/robot-ethics |access-date=2022-04-10 |website=www.ieee-ras.org}}</ref>

==History and events==
{{See also|History of robots}}
{{Robotic laws}}
Some of the central discussion of ethics in relation to the treatment of non-human or non-biological things and their potential "spirituality". Another central topic, has to do with the development of machinery and eventually robots, this philosophy was also applied to robotics. One of the first publications directly addressing and setting the foundation for robot ethics was [[Runaround (story)]], a science fiction short story written by [[Isaac Asimov]] in 1942 which featured his well known [[Three Laws of Robotics]]. These three laws were continuously altered by Asimov, and a fourth, or zeroth law, was eventually added to precede the first three,  in the context of his [[science fiction]] works. The short term "roboethics" was most likely coined by Gianmarco Veruggio.<ref name=Tzafestas-2016>{{cite book |last1=Tzafestas |first1=Spyros G. |title=Roboethics A Navigating Overview |date=2016 |publisher=Springer |location=Cham |isbn=978-3-319-21713-0 |page=1}}</ref>

An important event that propelled the concern of roboethics was the First International Symposium on Roboethics in 2004 by the collaborative effort of Scuola di Robotica, the Arts Lab of Scuola Superiore Sant'Anna, Pisa, and the Theological Institute of Pontificia Accademia della Santa Croce, Rome.<ref>{{Cite web|title=ROBOETHICS Cover|url=http://www.roboethics.org/sanremo2004/#:~:text=30th%20-%2031rd%20January,design%20and%20development%20of%20robots.|access-date=2020-09-29|website=www.roboethics.org}}</ref> Due to the activities of the school of Robotics which is a non profit organization and is to promote the knowledge of the science of Robotics among students, and the general public, this Roboethics Symposium was made. In discussions with students and non specialists, Gianmarco Veruggio and Fiorella Operto thought that it was necessary to spread correct conceptions among the general public about the alleged dangers in Robotics. They thought that a productive debate based on accurate insights and real knowledge could push people to take an active part in the education of public opinion, make them comprehend the positive uses of the new technology, and prevent its abuse. After two days of intense debating, anthropologist Daniela Cerqui identified three main ethical positions emerging from two days of intense debate:
#Those who are not interested in ethics. They consider that their actions are strictly technical, and do not think they have a social or a moral responsibility in their work.
#Those who are interested in short-term ethical questions. According to this profile, questions are expressed in terms of “good” or “bad,” and refer to some cultural values. For instance, they feel that robots have to adhere to social conventions. This will include “respecting” and helping humans in diverse areas such as implementing laws or in helping elderly people. (Such considerations are important, but we have to remember that the values used to define the “bad” and the “good” are relative. They are the contemporary values of the industrialized countries).
#Those who think in terms of long-term ethical questions, about, for example, the “Digital divide” between South and North, or young and elderly. They are aware of the gap between industrialized and poor countries, and wonder whether the former should not change their way of developing robotics to be more useful to the South. They do not formulate explicitly the question what for, but we can consider that it is implicit".<ref>{{cite web |url=http://www.roboethics.org/icra2005/veruggio.pdf |title=The Birth of Roboethics |first=Gianmarco |last=Veruggio |website=www.roboethics.org}}</ref>

These are some important events and projects in robot ethics. Further events in the field are announced by the [http://www.pt-ai.org/TG-ELS/projects euRobotics ELS topics group], and by [http://robohub.org/topic/Politics-Law-Society/ RoboHub]:

*1942: [[Isaac Asimov|Asimov]]'s short story "[[Runaround (story)|Runaround]]" explicitly states his Three Laws for the first time. These "Laws" will be reused in later works of robot-related science fiction by Asimov.
*2004: [https://web.archive.org/web/20070928113317/http://www.roboethics.org/sanremo04/index.php First International Symposium on Roboethics], organized by [http://www.scuoladirobotica.it/ School of Robotics], where the word Roboethics is officially used for the first time (30&ndash;31 January 2004, Villa Nobel, [[Sanremo]], [[Italy]]).
*2004: [https://web.archive.org/web/20061205195010/http://www.ncsu.edu/IEEE-RAS/_newras/ IEEE-RAS] establishes a [http://thth.berkeley.edu/tab-db/committeeinfo.php?tcid=19 Technical Committee on Roboethics].
*2004: Fukuoka World Robot Declaration (25 February 2004, [[Fukuoka, Fukuoka|Fukuoka]], [[Japan]]).<ref>{{cite web |title=World Robot Declaration |url=http://prw.kyodonews.jp/prwfile/prdata/0370/release/200402259634/index.html |website=Kyodo News}}</ref>
*2005: The IEEE RAS TC on Roboethics organizes the [https://web.archive.org/web/20070928113305/http://www.roboethics.org/icra05/index.php ICRA05] (International Conference on Robotics and Automation), a Workshop on Roboethics, (18 April 2005, [[Barcelona]], [[Spain]]).
*2005&ndash;2006: [https://web.archive.org/web/20070928113300/http://www.roboethics.org/atelier06/index.php E.C. Euron Roboethics Atelier]. [https://web.archive.org/web/20060614034251/http://www.euron.org/activities/projects/roboethics.html The Euron Project], coordinated by [http://www.scuoladirobotica.it School of Robotics], involved a large number of roboticists and scholars of humanities who produced the first Roadmap for a Roboethics (February/March 2006, [[Genoa]], [[Italy]])
*2006: [https://web.archive.org/web/20070202205529/http://www.biorob2006.org/home.html BioRob2006], the first IEEE / RAS-EMBS International Conference on Biomedical Robotics and Bio-mechatronics; Mini symposium on Roboethics (20 February 2006, [[Pisa]], [[Italy]]).
*2006: [https://web.archive.org/web/20061008055707/http://ethicbots.na.infn.it/workshop.htm International Workshop "Ethics of Human Interaction with Robotic, Bionic, and AI Systems: Concepts and Policies"]; supported by the [https://web.archive.org/web/20110721230729/http://ethicbots.na.infn.it/ ETHICBOTS] European Project (17&ndash;18 October 2006, [[Naples]], [[Italy]]).
*2007: [https://web.archive.org/web/20070704005125/http://www.roboethics.org/icra07/index.php The IEEE RAS TC on Roboethics organizes another Workshop on Roboethics], [http://www.icra07.org/ ICRA07] (International Conference on Robotics and Automation), (14 April 2007, [[Rome]], [[Italy]]).
*2007: [http://www.iaail.org/icail-2007/ ICAIL'07] {{Webarchive|url=https://web.archive.org/web/20080603232317/http://www.iaail.org/icail-2007/ |date=2008-06-03 }}, [http://www.informatik.uni-trier.de/~ley/db/conf/icail/icail2007.html International Conference on Artificial Intelligence and Law], (4–8 June 2007, [[Stanford University]], [[Palo Alto]], [[California|CA]], [[United States|USA]]).
*2007: [http://www.utwente.nl/ecap07/ International European Conference on Computing and Philosophy E-CAP ‘07] {{Webarchive|url=https://web.archive.org/web/20100701101950/http://www.utwente.nl/ecap07/ |date=2010-07-01 }}, track: "roboethics" (21&ndash;23 June 2007, [[University of Twente]], [[Netherlands]]).
*2007: [https://web.archive.org/web/20060614205951/http://cepe2007.sandiego.edu/index.asp Computer Ethics Philosophical Enquiry CEPE '07], topic: "Roboethics" (12&ndash;14 July 2007, [[University of San Diego]], [[California|CA]], [[United States|USA]]).
*2008: [http://www.roboethics.org/lincei2008/ INTERNATIONAL SYMPOSIUM ROBOTICS: NEW SCIENCE] (20 February 2008, Via della Lungara 10, [[Rome]], [[Italy]]).
*2009: [http://www.roboethics.org/icra2009/ The IEEE RAS TC on Roboethics organizes another Workshop on Roboethics], ICRA09 (International Conference on Robotics and Automation), (17 May 2009, [[Kobe]], [[Japan]]).
*2012: We Robot 2012 ([[University of Miami]], [[Florida|FL]], [[United States|USA]]).
*2013: Workshop on Robot Ethics (February  2013, [[University of Sheffield]], [[South Yorkshire]], [[England]]).
*2013: [http://conferences.law.stanford.edu/werobot/ We Robot 2013 - Getting Down to Business]  ([[Stanford University]], [[Palo Alto]], [[California|CA]], [[United States|USA]]).
*2014: [http://robots.law.miami.edu/2014/ We Robot 2014 - Risks and Opportunities]  ([[University of Miami]], [[Florida|FL]], [[United States|USA]],).
*2016: Ethical and Moral Considerations in Non-Human Agents, [[Stanford]] Spring Symposium, [[AAAI]] Association for the Advancement of Artificial Intelligence [https://sites.google.com/site/ethicalnonhumanagents/] ([[Stanford University]], [[Palo Alto]], [[California|CA]], [[United States|USA]]).
*2017: Future Investment Summit in [[Riyadh]]; a robot (called [[Sophia (robot)|Sophia]] and referred to with female pronouns) is granted [[Saudi Arabia]]n citizenship, becoming the first robot ever to have a nationality.<ref>{{cite news|url=http://www.newsweek.com/saudi-arabia-robot-sophia-muslim-694152|title=Saudi Arabia gives citizenship to a non-Muslim, English-Speaking robot|work=Newsweek|date=26 October 2017}}</ref><ref name=tc>{{cite news|url=https://techcrunch.com/2017/10/26/saudi-arabia-robot-citizen-sophia/|title=Saudi Arabia bestows citizenship on a robot named Sophia|work=TechCrunch|date=October 26, 2017|access-date=October 27, 2016}}</ref> This attracts controversy due to the ambiguity over several issues, e.g. whether Sophia can vote or marry, or whether a deliberate system shutdown is to be considered murder. Additionally, the juxtaposition of the rights afforded to Saudi women against the Saudi consideration of a robot to be a citizen will soon attract criticism from several news providers<ref>{{cite web|url=https://www.avclub.com/saudi-arabia-takes-terrifying-step-to-the-future-by-gra-1819888111|title=Saudi Arabia takes terrifying step to the future by granting a robot citizenship|work=AV Club|date=October 26, 2017|access-date=October 28, 2017}}</ref><ref>{{cite web|url=https://abcnews.go.com/International/saudi-arabia-criticized-giving-female-robot-citizenship-restricts/story?id=50741109 |title=Saudi Arabia criticized for giving female robot citizenship, while it restricts women's rights - ABC News |publisher=Abcnews.go.com |access-date=2017-10-28}}</ref> (25 October 2017, [[Riyadh]], Saudi Arabia).
*2017: The European Parliament passed a resolution addressed to the European Commission concerning Civil Law Rules on Robotics. <ref>{{Cite journal |last1=Iphofen |first1=Ron |last2=Kritikos |first2=Mihalis |date=2021-03-15 |title=Regulating artificial intelligence and robotics: ethics by design in a digital society |url=https://www.tandfonline.com/doi/full/10.1080/21582041.2018.1563803 |journal=Contemporary Social Science |language=en |volume=16 |issue=2 |pages=170–184 |doi=10.1080/21582041.2018.1563803 |s2cid=59298502 |issn=2158-2041}}</ref>
*2017: The [[AI Now Institute]] (AI Now) at [[New York University|NYU]], a research institute studying the social implications of artificial intelligence, is formed (15 November 2017, [[New York City|New York CIty]], [[New York (state)|NY]], [[United States|USA]]).
*2020: The establishment of the Non-Human Party, for the rights of robots, animals, and the wider non-human environment.<ref>{{cite web|url=https://nonhuman.party |title=Non-Human Party |year=2021}}</ref>
*2021: [https://werobot2021.com/ We Robot 2021] (23 Sep 2021,  [[University of Miami]], [[Florida|FL]], [[United States|USA]])
*2021: [https://www.ers-workshop.com/ IROS 2021 Workshop - Building and Evaluating Ethical Robotic Systems]

Computer scientist [[Virginia Dignum]] noted in a March 2018 issue of ''[[Ethics and Information Technology]]'' that the general societal attitude toward artificial intelligence (AI) has, in the modern era, shifted away from viewing AI as a tool and toward viewing it as an intelligent “team-mate”. In the same article, she assessed that, with respect to AI, ethical thinkers have three goals, each of which she argues can be achieved in the modern era with careful thought and implementation.<ref>{{Cite journal|last=Rahwan|first=Iyad|date=2018|title=Society-In-the-Loop: Programming the Algorithmic Social Contract|journal=Ethics and Information Technology|volume=20|pages=5–14|doi=10.1007/s10676-017-9430-8|arxiv=1707.07232|s2cid=3674879}}</ref><ref>{{Cite journal|last=Bryson|first=Joanna|date=2018|title=Patiency Is Not a Virtue: the Design of Intelligent Systems and Systems of Ethics|journal=Ethics and Information Technology|volume=20|pages=15–26|doi=10.1007/s10676-018-9448-6|doi-access=free}}</ref><ref>{{Cite journal|last1=Vamplew|first1=Peter|last2=Dazeley|first2=Richard|last3=Foale|first3=Cameron|last4=Firmin|first4=Sally|date=2018|title=Human-Aligned Artificial Intelligence Is a Multiobjective Problem|url=http://researchonline.federation.edu.au/vital/access/HandleResolver/1959.17/164225|journal=Ethics and Information Technology|volume=20|pages=27–40|doi=10.1007/s10676-017-9440-6|hdl=1959.17/164225|s2cid=3696067}}</ref><ref>{{Cite journal|last1=Bonnemains|first1=Vincent|last2=Saurel|first2=Claire|last3=Tessier|first3=Catherine|date=2018|title=Embedded Ethics: Some Technical and Ethical Challenges.|url=https://hal.archives-ouvertes.fr/hal-01697137/file/Embedded_Ethics_complete.pdf|journal=Ethics and Information Technology|volume=20|pages=41–58|doi=10.1007/s10676-018-9444-x|s2cid=3697093}}</ref><ref>{{Cite journal|last1=Arnold|first1=Thomas|last2=Scheutz|first2=Matthias|date=2018|title=The 'Big Red Button' Is Too Late: An Alternative Model for the Ethical Evaluation of AI Systems|journal=Ethics and Information Technology|volume=20|pages=59–69|doi=10.1007/s10676-018-9447-7|s2cid=3582967}}</ref> The three ethical goals are as follows:

* Ethics ''by'' Design (the technical/algorithmic integration of ethical reasoning capabilities as part of the behavior of artificial autonomous system—see [[Machine ethics|Machine Ethics]]);
* Ethics ''in'' Design (the regulatory and engineering methods that support the analysis and evaluation of the ethical implications of AI systems as these integrate or replace traditional social structures); and
* Ethics ''for'' design (the codes of conduct, standards and certification processes that ensure the integrity of developers and users as they research, design, construct, employ and manage artificial intelligent systems—see [[Robot ethics#Robot Ethics and Law|Robot Ethics and Law]] below).<ref>{{Cite journal|last=Dignum|first=Virginia|date=2018|title=Ethics in Artificial Intelligence: Introduction to the Special Issue|journal=Ethics and Information Technology|volume=20|pages=1–3|doi=10.1007/s10676-018-9450-z|doi-access=free}}</ref>

==In popular culture==
{{main|Artificial intelligence in fiction}}
Roboethics as a science or philosophical topic has begun to be a common theme in science fiction literature and films. One film that could be argued to be ingrained in pop culture that depicts the dystopian future use of robotic AI  is ''[[The Matrix]]'', depicting a future where humans and conscious sentient AI struggle for control of planet earth resulting in the destruction of most of the human race. An animated film based on ''The Matrix'', the ''[[Animatrix]]'', focused heavily on the potential ethical issues and insecurities between humans and robots. The movie is broken into short stories. Animatrix's animated shorts are also named after Isaac Asimov's fictional stories.

Another facet of roboethics is specifically concerned with the treatment of robots by humans, and has been explored in numerous films and television shows. One such example is [[Star Trek: The Next Generation]], which has a humanoid android, named [[Data (Star Trek)|Data]], as one of its main characters. For the most part, he is trusted with mission critical work, but his ability to fit in with the other living beings is often in question.<ref>{{Cite journal|last=Short|first=Sue|date=2003-01-01|title=The Measure of a Man?: Asimov's Bicentennial Man, Star Trek's Data, and Being Human|journal=Extrapolation|volume=44|issue=2|pages=209–223|doi=10.3828/extr.2003.44.2.6|issn=0014-5483}}</ref> More recently, the movie [[Ex Machina (film)|Ex Machina]] and TV show [[Westworld (TV series)|Westworld]] have taken on these ethical questions quite directly by depicting hyper-realistic robots that humans treat as inconsequential commodities.<ref>{{Cite news|url=https://psmag.com/news/can-westworld-give-us-new-ways-of-talking-about-slavery|title=Can 'Westworld' Give Us New Ways of Talking About Slavery?|last=Staff|first=Pacific Standard|website=Pacific Standard|language=en|access-date=2019-09-16}}</ref><ref>{{Cite web|url=https://www.theatlantic.com/entertainment/archive/2015/04/ex-machina-and-the-virtues-of-humanizing-artificial-intelligence/390279/|title=How 'Ex Machina' Stands Out for Not Fearing Artificial Intelligence|last=Parker|first=Laura|date=2015-04-15|website=The Atlantic|language=en-US|access-date=2019-09-16}}</ref> The questions surrounding the treatment of engineered beings has also been key component of [[Blade Runner (franchise)]] for over 50 years.<ref>{{Cite news|url=https://psmag.com/news/meaning-of-life-blade-runner-2049|title=The Meaning of Life in 'Blade Runner 2049'|last=Kilkenny|first=Katie|website=Pacific Standard|language=en|access-date=2019-09-16}}</ref> Films like [[Her (film)|Her]] have even distilled the human relationship with robots even further by removing the physical aspect and focusing on emotions.

Although not a part of roboethics ''per se'', the ethical behavior of robots themselves has also been a joining issue in roboethics in popular culture. The ''[[Terminator (franchise)|Terminator]]'' series focuses on robots run by an conscious AI program with no restraint on the termination of its enemies. This series too has the same archetype as ''The Matrix'' series, where robots have taken control. Another famous pop culture case of robots or AI without programmed ethics or morals is [[HAL 9000]] in the ''[[Space Odyssey]]'' series, where HAL (a computer with advanced AI capabilities who monitors and assists humans on a space station) kills all the humans on board to ensure the success of the assigned mission after his own life is threatened.<ref>{{Cite book|url=https://www.taylorfrancis.com/books/9781315591070|title=Killer Robots: Legality and Ethicality of Autonomous Weapons|last=Krishnan|first=Armin|doi=10.4324/9781315591070|access-date=2019-09-16|year=2016|isbn=9781315591070|publisher=Routledge}}</ref>

== Killer robots ==

[[Lethal autonomous weapon|Lethal Autonomous Weapon Systems]] (LAWS) which is often called “killer robots,” are theoretically able to target and fire without human supervision and interference. In 2014, the Convention on Conventional Weapons (CCW) held two meetings. The first was the Meeting of Experts on Lethal Autonomous Weapons Systems (LAWS). This meeting was about the special mandate on LAWS and intrigued intense discussion.<ref>{{Cite web |title=2014 |url=https://reachingcriticalwill.org/disarmament-fora/ccw/2014 |access-date=2022-04-03 |website=reachingcriticalwill.org}}</ref> National delegations and many non-governmental organizations(NGOs) expressed their opinions on the matter.

Numerous NGOs and certain states such as [[Pakistan]] and [[Cuba]] are calling for a preventive prohibition of LAWS. They proposed their opinions based on deontological and consequentialist reasoning. On the deontological side, certain philosophers such as Peter Asaro and Robert Sparrow, most NGOs, and the Vatican all argue that authorizing too much rights to machine violates human dignity, and that people have the “right not to be killed by a machine.” To support their standpoint, they repeatedly cite the [[Martens Clause]].

In the end of this meeting, the most important consequentialist objection was that LAWS would never be able to respect international humanitarian law (IHL), as believed by NGOs, many researchers, and several states ([[Pakistan]], [[Austria]], [[Egypt]], [[Mexico]]).

According to the [[International Committee of the Red Cross]](ICRC), “there is no doubt that the development and use of autonomous weapon systems in armed conflict is governed by international humanitarian law.”<ref>{{Cite journal |date=December 2020 |title=International Committee of the Red Cross (ICRC) position on autonomous weapon systems: ICRC position and background paper |url=http://dx.doi.org/10.1017/s1816383121000564 |journal=International Review of the Red Cross |volume=102 |issue=915 |pages=1335–1349 |doi=10.1017/s1816383121000564 |s2cid=244396800 |issn=1816-3831}}</ref> States recognize this: those who participated in the first UN Expert Meeting in May 2014 recognized respect for IHL as an essential condition for the implementation of LAWS. With diverse predictions, certain states believe LAWS will be unable to meet this criterion, while others underline the difficulty of adjudicating at this stage without knowing the weapons' future capabilities ([[Japan]], [[Australia]]). All insist equally on the ''ex-ante'' verification of the systems' conformity to IHL before they are put into service, in virtue of article of the first additional protocol to the Geneva Conventions.

=== Degree of human control ===
Three classifications of the degree of human control of autonomous weapon systems were laid out by [[Bonnie Docherty]] in a 2012 [[Human Rights Watch]] report.<ref name=army-autonomous>{{cite web|url=https://www.armyupress.army.mil/Journals/Military-Review/English-Edition-Archives/May-June-2017/Pros-and-Cons-of-Autonomous-Weapons-Systems/|title=Pros and Cons of Autonomous Weapons Systems|author1=Amitai Etzioni|author2=Oren Etzioni|work=army.mil|date=June 2017}}</ref>
*[[human-in-the-loop]]: a human must instigate the action of the weapon (in other words not fully autonomous)
*human-on-the-loop: a human may abort an action
*human-out-of-the-loop: no human action is involved

== Sex robots ==
In 2015, the Campaign Against Sex Robots (CASR) was launched to draw attention to the [[Sexual intercourse|sexual relationship]] of humans with machines. The campaign claims that [[sex robot]]s are potentially harmful and will contribute to [[Social inequality|inequalities]] in society, and that an organized approach and ethical response against the development of sex robots is necessary.<ref>{{Cite magazine |last=Temperton |first=James |date=2015-09-15 |title=Campaign calls for ban on sex robots |language=en-GB |magazine=[[Wired UK]] |url=https://www.wired.co.uk/article/campaign-against-sex-robots |access-date=2022-08-07 |issn=1357-0978}}</ref>

In the article ''Should We Campaign Against Sex Robots?'', published by the [[MIT Press]], researchers pointed some flaws on this campaign and did not support a ban on sex robots completely. Firstly, they argued that the particular claims advanced by the CASR were "unpersuasive," partly because of a lack of clarity about the campaign's aims and partly because of substantive defects in the main ethical objections put forward by campaign's founders. Secondly, they argued that it would be very difficult to endorse a general campaign against sex robots unless one embraced a highly [[Conservatism|conservative]] attitude towards the ethics of sex. Drawing upon the example of the campaign to stop killer robots, they thought that there were no inherently bad properties of sex robots that give rise to similarly serious levels of concern, the harm caused by sex robots being speculative and indirect. Nonetheless, the article concedes that there are legitimate concerns that can be raised about the development of sex robots.<ref>{{Citation |last1=Danaher |first1=John |title=Should We Campaign Against Sex Robots? |date=2017 |url=https://philpapers.org/rec/DANSWC |work=Robot Sex: Social and Ethical Implications |editor-last=Danaher |editor-first=John |publisher=Cambridge, MA: MIT Press |access-date=2022-04-16 |last2=Earp |first2=Brian D. |last3=Sandberg |first3=Anders |editor2-last=McArthur |editor2-first=Neil}}</ref>

==Law==

With contemporary technological issues emerging as society pushes on, one topic that requires thorough thought is robot ethics concerning the law. Academics have been debating the process of how a government could go about creating legislation with robot ethics and law. A pair of scholars that have been asking these questions are Neil M. Richards Professor of Law at [[Washington University School of Law]] as well as, William D. Smart Associate Professor of Computer Science at [[McKelvey School of Engineering]]. In their paper "How Should Robots Think About Law" they make four main claims concerning robot ethics and law.<ref>{{cite SSRN |last1=Richards |first1=Neil M. |last2=Smart |first2=William D. |title=How Should the Law Think About Robots? |date=2013 |ssrn=2263363 }}</ref> The groundwork of their argument lies on the definition of robot as "non-biological autonomous agents that we think captures the essence of the regulatory and technological challenges that robots present, and which could usefully be the basis of regulation." Second, the pair explores the future advanced capacities of robots within around a decades time. Their third claim argues a relation between the legal issues robot ethics and law experiences with the legal experiences of cyber-law. Meaning that robot ethics laws can look towards cyber-law for guidance. The "lesson" learned from cyber-law being the importance of the metaphors we understand emerging issues in technology as. This is based on if we get the metaphor wrong for example, the legislation surrounding the emerging technological issue is most likely wrong. The fourth claim they argue against is a metaphor that the pair defines as "The Android Fallacy". They argue against the android fallacy which claims humans and non-biological entities are "just like people".

==Empirical research==
There is mixed evidence as to whether people judge robot behavior similarly to humans or not. Some evidence indicates that people view bad behavior negatively and good behavior positively regardless of whether the agent of the behavior is a human or a robot; however, robots receive less credit for good behavior and more blame for bad behavior.<ref>{{cite journal |last1=Banks |first1=Jaime |title=Good Robots, Bad Robots: Morally Valenced Behavior Effects on Perceived Mind, Morality, and Trust |journal=International Journal of Social Robotics |date=2020-09-10 |volume=13 |issue=8 |pages=2021–2038 |doi=10.1007/s12369-020-00692-3 |doi-access=free }}</ref> Other evidence suggests that malevolent behavior by robots is seen as more morally wrong than benevolent behavior is seen as morally right; malevolent robot behavior is seen as more intentional than benevolent behavior.<ref>{{cite journal |last1=Swiderska |first1=Aleksandra |last2=Küster |first2=Dennis |title=Robots as Malevolent Moral Agents: Harmful Behavior Results in Dehumanization, Not Anthropomorphism |journal=Cognitive Science |date=2020 |volume=44 |issue=7 |pages=e12872 |doi=10.1111/cogs.12872 |pmid=33020966 |s2cid=220429245 |doi-access=free }}</ref>  In general, people's moral judgments of both robots and humans are based on the same justifications and concepts but people have different moral expectations when judging humans and robots.<ref>{{cite book |last1=Voiklis |first1=John |last2=Kim |first2=Boyoung |last3=Cusimano |first3=Corey |last4=Malle |first4=Bertram F. |title=2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) |chapter=Moral judgments of human vs. Robot agents |date=August 2016 |pages=775–780 |doi=10.1109/ROMAN.2016.7745207|isbn=978-1-5090-3929-6 |s2cid=25295130 }}</ref> Research has also found that when people try to interpret and understand how robots decide to behave in a particular way, they may see robots as using rules of thumb (advance the self, do what is right, advance others, do what is logical, and do what is normal) that align with established ethical doctrines (egotism, deontology, altruism, utilitarianism, and normative).<ref>{{cite journal |last1=Banks |first1=Jaime |last2=Koban |first2=Kevin |title=Framing Effects on Judgments of Social Robots' (Im)Moral Behaviors |journal=Frontiers in Robotics and AI |date=2021 |volume=8 |page=627233 |doi=10.3389/frobt.2021.627233|pmid=34041272 |pmc=8141842 |doi-access=free }}</ref>

==See also==
*[[Machine ethics]]
*[[Robot rights]]
*[[Robotics]]
*[[Ethics of artificial intelligence]]

== Notes ==
{{reflist}}

==References==
* Levy, David (November, 2008). ''[[Love and Sex with Robots|Love and Sex with Robots: The Evolution of Human-Robot Relationships]]''. [[Harper Perennial]].
* Richards, Neil M.; Smart, William D. (2013). How should the law think about robots?: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2263363
* Jean-Baptiste Jeangène Vilmer (March 23, 2015)Terminator Ethics: Should We Ban “Killer Robots”?: https://www.ethicsandinternationalaffairs.org/2015/terminator-ethics-ban-killer-robots/
* John Danaher, Brian D. Earp and Anders Sandberg.(2017) [https://philpapers.org/rec/DANSWC Should we campaign against sex robots?]

==Further reading==
* Lin, Patrick/Abney, Keith/Bekey, George A. (December, 2011).  ''Robot Ethics: The Ethical and Social Implications of Robotics''.  [[MIT Press]].
* {{cite book |title=Roboethics A Navigating Overview |date=2016 |publisher=Springer |isbn=978-3-319-21713-0|location=Berlin |last1=Tzafestas |first1=Spyros G. }}

==External links==
*[http://philpapers.org/browse/robot-ethics PhilPapers] - the standard bibliography on roboethics is on
*[http://ethics.calpoly.edu/robots.htm Ethics + Emerging Sciences Group]
*[http://www.scu.edu/ethics/ The Markkula Center for Applied Ethics at Santa Clara University, USA]
*[http://www.pt-ai.org/TG-ELS/policy List of organisations and conferences] from ''euRobotics'' topics group "ethical, legal and socio-economic issues" (ELS)
*[http://www.roboethics.org/ Conference list on the "Roboethics" Website] (up to 2009)
*IEEE [http://www.ieee-ras.org/robot-ethics Technical Committee on Roboethics]
*[http://www.pt-ai.org/TG-ELS/ euRobotics topics group "ethical, legal and social issues" (ELS)]
*[http://inseit.net/ International Society for Ethics and Information Technology]
*[http://www.cpsr.org/about/ Computer Professionals for Social Responsibility]
*[http://responsiblerobotics.org/ Responsible Robotics]
*[http://www.iihl.org The International Institute of Humanitarian Law]
*[http://www.ucsusa.org/ Union of Concerned Scientists]
*[http://www.amoon.ca/Roboethics/ Roboethics Info Database]
*[http://icie.zkm.de/ International Center for Information Ethics]
*[http://www.physorg.com/news164887377.html Living Safely with Robots, Beyond Asimov's Laws], ''PhysOrg.com'', June 22, 2009.
*[http://www.plugandpray-film.com/en/ Plug & Pray, documentary film on the ethics of robotics and artificial intelligence (with Joseph Weizenbaum and Ray Kurzweil)]
*[http://mechanicaldesign101.com/2016/11/05/robot-ethics/ Prof. Bruno Siciliano, co-editor of the Springer Handbook of Robotics, discusses roboethics as part of his TEDx talk.]
* [https://whatis.techtarget.com/definition/roboethics-robot-ethics]
* [https://www.ethicsandinternationalaffairs.org/2015/terminator-ethics-ban-killer-robots/ Terminator Ethics: Should We Ban “Killer Robots”?]
{{Robotics}}
{{emerging technologies|topics=yes}}

[[Category:Philosophy of artificial intelligence]]
[[Category:Singularitarianism]]
[[Category:Emerging technologies]]
[[Category:Ethics of science and technology]]
[[Category:Regulation of robots]]