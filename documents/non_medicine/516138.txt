{{short description|Belief in an incipient technological singularity}}
{{Transhumanism}}
'''Singularitarianism''' is a [[Social movement|movement]] defined by the belief that a [[technological singularity]]—the creation of [[superintelligence]]—will likely happen in the medium future, and that deliberate action ought to be taken to ensure that the singularity benefits [[human]]s.<ref name="time immortal" />

Singularitarians are distinguished from other [[futurist]]s who speculate on a technological singularity by their belief that the singularity is not only possible, but desirable if guided prudently. Accordingly, they may sometimes dedicate their lives to acting in ways they believe will contribute to its rapid yet safe realization.<ref name="Kurzweil 2005">{{cite book| last = Kurzweil | first = Raymond | title = [[The Singularity Is Near|The Singularity Is Near: When Humans Transcend Biology]] | publisher = Viking Adult| year = 2005 | isbn = 0-670-03384-7| oclc = 224517172}}</ref>

''[[Time (magazine)|Time]]'' magazine describes the worldview of Singularitarians by saying "even though it sounds like science fiction, it isn't, no more than a weather forecast is science fiction. It's not a fringe idea; it's a serious hypothesis about the future of life on Earth. There's an intellectual gag reflex that kicks in anytime you try to swallow an idea that involves super-intelligent immortal cyborgs, but... while the Singularity appears to be, on the face of it, preposterous, it's an idea that rewards sober, careful evaluation".<ref name="time immortal">[http://content.time.com/time/magazine/article/0,9171,2048299,00.html  "2045: The Year Man Becomes Immortal"] Time Magazine, February 2011</ref>

==Definition==
The term "Singularitarian" was originally defined by [[Extropianism|Extropian]] thinker Mark Plus (Mark Potts) in 1991 to mean "one who believes the concept of a Singularity".{{cn|date=October 2018}} This term has since been redefined to mean "Singularity activist" or "friend of the Singularity"; that is, one who acts so as to bring about the singularity.<ref>{{cite web|author=Extropy Institute |url=http://www.extropy.org/neologo.htm#s |title=Neologisms of Extropy |publisher=Extropy.org |access-date=2011-03-30}}</ref> 

Singularitarianism can also be thought of as an orientation or an outlook that prefers the enhancement of human intelligence as a specific [[transhumanism|transhumanist]] goal instead of focusing on specific technologies such as A.I.<ref name=":0">{{Cite book|title=Cyborg Selves: A Theological Anthropology of the Posthuman|last=Thweatt-Bates|first=Jeanine|publisher=Routledge|year=2016|isbn=978-1-4094-2141-2|location=Oxon|page=52}}</ref> There are also definitions that identify a singularitarian as an activist or a friend of the concept of singularity, that is, one who acts so as to bring about a singularity.<ref>{{Cite book|title=The Singularity is Near|last=Kurzweil|first=Ray|publisher=Gerald Duckworth & Co|year=2010|isbn=978-0-7156-4015-9|location=London}}</ref> Some sources described it as a [[Ethics|moral philosophy]] that advocates deliberate action to bring about and steer the development of a superintelligence that will lead to a theoretical future point that emerges during a time of accelerated change.<ref>{{Cite web|url=https://ieet.org/index.php/tpwiki/Singularitarianism|title=Singularitarianism {{!}} Technoprogressive Wiki|website=ieet.org|access-date=2018-10-26}}</ref>

Inventor and futurist [[Ray Kurzweil]], author of the 2005 book ''[[The Singularity Is Near|The Singularity Is Near: When Humans Transcend Biology]]'', defines a Singularitarian as someone "who understands the Singularity and who has reflected on its implications for his or her own life"<ref name="Kurzweil 2005" /> and estimates [[The Singularity Is Near#2045: The Singularity|the singularity will occur around 2045]].<ref name="Kurzweil 2005" />

==History==
An early singularitarian articulation that history is making progress toward a point of superhuman intelligence is found in [[Hegel]]'s work, ''The Phenomenology of Spirit''.<ref name="Eden Moor Soraker Steinhart 2013 p. 6">{{cite book | last=Eden | first=A.H. | last2=Moor | first2=J.H. | last3=Soraker | first3=J.H. | last4=Steinhart | first4=E. | title=Singularity Hypotheses: A Scientific and Philosophical Assessment | publisher=Springer Berlin Heidelberg | series=The Frontiers Collection | year=2013 | isbn=978-3-642-32560-1 | url=https://books.google.com/books?id=gVxGAAAAQBAJ&pg=PA6 | access-date=2023-05-05 | page=6}}</ref> In 1993, [[mathematician]], [[computer scientist]], and [[science fiction]] author [[Vernor Vinge]] hypothesized that the moment might come when technology will allow "creation of entities with greater than human intelligence"<ref>[http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html The Coming Technological Singularity: How to Survive in the Post-Human Era], by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.</ref> and used the term "the Singularity" to describe this moment.<ref name="nytimes july09"/> He suggested that the singularity may pose an [[existential risk]] for humanity, and that it could happen through one of four means:

#The development of computers that are "awake" and superhumanly intelligent. 
#Large computer networks (and their associated users) may "wake up" as a superhumanly intelligent entity.
#Computer/human interfaces may become so intimate that users may reasonably be considered superhumanly intelligent.
#Biological science may find ways to improve upon the natural human intellect.<ref>[http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html The Coming Technological Singularity: How to Survive in the Post-Human Era], by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.</ref> 

Singularitarianism coalesced into a coherent ideology in 2000, when [[artificial intelligence]] (AI) researcher [[Eliezer Yudkowsky]] wrote ''The Singularitarian Principles'',<ref name="Kurzweil 2005"/><ref name="yudkowsky1">[http://www.yudkowsky.net/obsolete/principles.html Singularitarian Principles]"</ref> in which he stated that a Singularitarian believes that the singularity is a secular, non-mystical event which is possible and beneficial to the world and is worked towards by its adherents.<ref name="yudkowsky1"/> Yudkowsky's conceptualization of singularity offered a broad definition developed to be inclusive of various interpretations.<ref name=":0" /> There are theorists such as Michael Anissimov who argued for a strict definition, one that refers only to the advocacy of the development of posthuman (greater than human) intelligence.<ref name=":0" /> 

In June 2000 Yudkowsky, with the support of [[Internet entrepreneur]]s Brian Atkins and Sabine Atkins, founded the [[Machine Intelligence Research Institute]] to work towards the creation of self-improving [[Friendly artificial intelligence|Friendly AI]]. MIRI's writings argue for the idea that an AI with the ability to improve upon its own design ([[Intelligence explosion|Seed AI]]) would rapidly lead to [[superintelligence]]. These Singularitarians believe that reaching the singularity swiftly and safely is the best possible way to minimize net [[existential risk]].

Many people believe a technological singularity is possible without adopting Singularitarianism as a moral philosophy. Although the exact numbers are hard to quantify, Singularitarianism is a small movement, which includes [[transhumanism|transhumanist]] philosopher [[Nick Bostrom]]. Inventor and futurist [[Ray Kurzweil]], who predicts that the [[The Singularity Is Near#2045: The Singularity|Singularity will occur circa 2045]], greatly contributed to popularizing Singularitarianism with his 2005 book ''[[The Singularity Is Near|The Singularity Is Near: When Humans Transcend Biology ]]''.<ref name="Kurzweil 2005"/>

{{quote|What, then, is the Singularity? It's a future period during which the pace of technological change will be so rapid, its impact so deep, that human life will be irreversibly transformed. Although neither utopian or dystopian, this epoch will transform the concepts we rely on to give meaning to our lives, from our business models to the cycle of human life, including death itself. Understanding the Singularity will alter our perspective on the significance of our past and the ramifications for our future. To truly understand it inherently changes one's view of life in general and one's particular life. I regard someone who understands the Singularity and who has reflected on its implications for his or her own life as a "singularitarian."<ref name="Kurzweil 2005"/>}}

With the support of [[NASA]], [[Google]], and a broad range of [[technology forecasting|technology forecasters]] and [[technocapitalism|technocapitalists]], the [[Singularity University]] opened in June 2009 at the [[NASA Research Park]] in [[Silicon Valley]] with the goal of preparing the next generation of leaders to address the challenges of [[accelerating change]].

In July 2009, many prominent Singularitarians participated in a conference organized by the [[Association for the Advancement of Artificial Intelligence]] (AAAI) to discuss the potential impact of [[robot]]s and computers and the impact of the hypothetical possibility that they could become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard (i.e., [[cybernetic revolt]]). They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They warned that some [[computer viruses]] can evade elimination and have achieved "cockroach intelligence". They asserted that self-awareness as depicted in [[science fiction]] is probably unlikely, but that there were other potential hazards and pitfalls.<ref name="nytimes july09">{{Cite news |url=https://www.nytimes.com/2009/07/26/science/26robot.html |title=Scientists Worry Machines May Outsmart Man |first=John |last=Markoff |work=New York Times |date=July 26, 2009}}</ref> Some experts and academics have questioned the use of [[military robot|robots for military combat]], especially when such robots are given some degree of autonomous functions.<ref>{{Cite news |url=http://news.bbc.co.uk/2/hi/technology/8182003.stm |title=Call for debate on killer robots |first=Jason |last=Palmer |work=BBC News |date=3 August 2009}}</ref> The President of the AAAI has commissioned a study to look at this issue.<ref>[http://research.microsoft.com/en-us/um/people/horvitz/AAAI_Presidential_Panel_2008-2009.htm AAAI Presidential Panel on Long-Term AI Futures 2008-2009 Study], Association for the Advancement of Artificial Intelligence, Accessed 7/26/09.</ref>

==Reception==
There are several objections to Kurzweil's singularitarianism, and these even include criticisms from optimists within the A.I. field. For instance, [[Pulitzer Prize]] winning author [[Douglas Hofstadter]] argued that Kurzweil's predicted achievement of human-level A.I. by 2045 is not viable.<ref name=":1">{{Cite book|title=The Oxford Handbook of Philosophy of Cognitive Science|last1=Margolis|first1=Eric|last2=Samuels|first2=Richard|last3=Stitch|first3=Stephen|publisher=Oxford University Press|year=2012|isbn=978-0-19-530979-9|location=Oxford|page=169}}</ref> Even [[Gordon Moore]], who is credited for introducing the [[Moore's law|Moore's Law]] that predicated<ref>{{Cite news|url=https://www.nytimes.com/2016/04/07/science/artificial-intelligence-when-is-the-singularity.html|title=When Is the Singularity? Probably Not in Your Lifetime|last=Lazar|first=Zohar|date=April 7, 2016|work=The New York Times|access-date=2018-10-26|language=en}}</ref> the notion of singularity, maintained that it will never occur.<ref>{{Cite news|url=https://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity|title=Tech Luminaries Address Singularity |work=IEEE Spectrum |date=1 June 2008 |access-date=2018-10-26|language=en}}</ref> According to some observers, these criticisms do not diminish enthusiasm for singularity because it has assumed a quasi-religious response to the fear of death, allowing its adherents to enjoy the benefits of religion without its ontological burdens.<ref name=":1" /> Science journalist [[John Horgan (journalist)|John Horgan]] provided more insights into this notion as he likened singularitarianism to a religion:
{{quote|Let's face it. The singularity is a religious rather than a scientific vision. The science-fiction writer Ken MacLeod has dubbed it "the rapture for nerds," an allusion to the end-time, when Jesus whisks the faithful to heaven and leaves us sinners behind. Such yearning for transcendence, whether spiritual or technological, is all too understandable. Both as individuals and as a species, we face deadly serious problems, including terrorism, nuclear proliferation, overpopulation, poverty, famine, [[environmental degradation]], [[climate change]], [[resource depletion]], and [[AIDS]]. Engineers and scientists should be helping us face the world's problems and find solutions to them, rather than indulging in escapist, pseudoscientific fantasies like the singularity.<ref name="Horgan 2008">{{cite magazine | last = Horgan | first = John | author-link = John Horgan (American journalist) | title = The Consciousness Conundrum | year = 2008 | url = https://spectrum.ieee.org/the-consciousness-conundrum |magazine=IEEE Spectrum}}</ref>}}

Kurzweil rejects this categorization, stating that his predictions about the singularity are driven by the data that increases in computational technology have been exponential in the past.<ref>{{Cite news |url=https://online.wsj.com/news/articles/SB10001424127887324504704578412581386515510 |title=Will Google's Ray Kurzweil Live Forever? |work=[[Wall Street Journal]] |date=April 12, 2013 |first=Holman |last=W. Jenkins, Jr.}}</ref> He also claimed that critics who challenge his view mistakenly take an intuitive linear view of technological advancement.<ref>{{Cite book|title=Cyber-Humans: Our Future with Machines|last=Barfield|first=Woodrow|publisher=Springer|year=2015|isbn=978-3-319-25048-9|location=Cham, Switzerland|page=40}}</ref>

==See also==
* [[Artificial general intelligence]]
* [[Eschatology]]
* [[Existential risk from artificial general intelligence]]
* [[Global brain]]
* [[Intelligence explosion]]
* [[Outline of transhumanism]]
* [[Post-scarcity economy]]
* [[Technological utopianism]]

==References==
{{reflist|30em}}

== External links ==
* [http://www.nickbostrom.com/ethics/ai.html Ethical Issues in Advanced Artificial Intelligence] by [[Nick Bostrom]], 2003
* [https://spectrum.ieee.org/the-consciousness-conundrum "The Consciousness Conundrum"], a criticism of singularitarians by [[John Horgan (American journalist)|John Horgan]]

[[Category:Singularitarianism| ]]
[[Category:Philosophy of artificial intelligence]]
[[Category:Systems thinking]]
[[Category:Technology forecasting]]
[[Category:Technology neologisms]]
[[Category:Transhumanism]]